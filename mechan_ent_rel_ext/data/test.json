{"text": "Non-autoregressive (NAR) neural machine translation is usually done via knowledge distillation from an autoregressive (AR) model. Under this framework, we leverage large monolingual corpora to improve the NAR model\u2019s performance, with the goal of transferring the AR model\u2019s generalization ability while preventing overfitting. On top of a strong NAR baseline, our experimental results on the WMT14 En-De and WMT16 En-Ro news translation tasks confirm that monolingual data augmentation consistently improves the performance of the NAR model to approach the teacher AR model\u2019s performance, yields comparable or better results than the best non-iterative NAR methods in the literature and helps reduce overfitting in the training process.", "tokens": ["Non-autoregressive", "(", "NAR", ")", "neural", "machine", "translation", "is", "usually", "done", "via", "knowledge", "distillation", "from", "an", "autoregressive", "(", "AR", ")", "model", ".", "Under", "this", "framework", ",", "we", "leverage", "large", "monolingual", "corpora", "to", "improve", "the", "NAR", "model", "\u2019s", "performance", ",", "with", "the", "goal", "of", "transferring", "the", "AR", "model", "\u2019s", "generalization", "ability", "while", "preventing", "overfitting", ".", "On", "top", "of", "a", "strong", "NAR", "baseline", ",", "our", "experimental", "results", "on", "the", "WMT14", "En-De", "and", "WMT16", "En-Ro", "news", "translation", "tasks", "confirm", "that", "monolingual", "data", "augmentation", "consistently", "improves", "the", "performance", "of", "the", "NAR", "model", "to", "approach", "the", "teacher", "AR", "model", "\u2019s", "performance", ",", "yields", "comparable", "or", "better", "results", "than", "the", "best", "non-iterative", "NAR", "methods", "in", "the", "literature", "and", "helps", "reduce", "overfitting", "in", "the", "training", "process", "."], "entities": [{"type": "Operation", "start": 26, "end": 30, "text": "leverage large monolingual corpora", "sent_idx": 1}, {"type": "Effect", "start": 36, "end": 37, "text": "performance", "sent_idx": 1}, {"type": "Effect", "start": 51, "end": 52, "text": "overfitting", "sent_idx": 1}, {"type": "Operation", "start": 76, "end": 79, "text": "monolingual data augmentation", "sent_idx": 2}, {"type": "Effect", "start": 82, "end": 83, "text": "performance", "sent_idx": 2}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Neg_Affect", "head": 0, "tail": 2}, {"type": "Pos_Affect", "head": 3, "tail": 4}], "id": "abstract-2020--acl-main--171"}
{"text": "Deep attention models have advanced the modelling of sequential data across many domains. For language modelling in particular, the Transformer-XL \u2014 a Transformer augmented with a long-range memory of past activations \u2014 has been shown to be state-of-the-art across a variety of well-studied benchmarks. The Transformer-XL incorporates a long-range memory at every layer of the network, which renders its state to be thousands of times larger than RNN predecessors. However it is unclear whether this is necessary. We perform a set of interventions to show that comparable performance can be obtained with 6X fewer long range memories and better performance can be obtained by limiting the range of attention in lower layers of the network.", "tokens": ["Deep", "attention", "models", "have", "advanced", "the", "modelling", "of", "sequential", "data", "across", "many", "domains", ".", "For", "language", "modelling", "in", "particular", ",", "the", "Transformer-XL", "\u2014", "a", "Transformer", "augmented", "with", "a", "long-range", "memory", "of", "past", "activations", "\u2014", "has", "been", "shown", "to", "be", "state-of-the-art", "across", "a", "variety", "of", "well-studied", "benchmarks", ".", "The", "Transformer-XL", "incorporates", "a", "long-range", "memory", "at", "every", "layer", "of", "the", "network", ",", "which", "renders", "its", "state", "to", "be", "thousands", "of", "times", "larger", "than", "RNN", "predecessors", ".", "However", "it", "is", "unclear", "whether", "this", "is", "necessary", ".", "We", "perform", "a", "set", "of", "interventions", "to", "show", "that", "comparable", "performance", "can", "be", "obtained", "with", "6X", "fewer", "long", "range", "memories", "and", "better", "performance", "can", "be", "obtained", "by", "limiting", "the", "range", "of", "attention", "in", "lower", "layers", "of", "the", "network", "."], "entities": [{"type": "Operation", "start": 48, "end": 49, "text": "Transformer-XL", "sent_idx": 2}, {"type": "Effect", "start": 93, "end": 94, "text": "performance", "sent_idx": 4}, {"type": "Operation", "start": 110, "end": 121, "text": "limiting the range of attention in lower layers of the network", "sent_idx": 4}, {"type": "Effect", "start": 105, "end": 106, "text": "performance", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 2, "tail": 3}], "id": "abstract-2020--acl-main--672"}
{"text": "Although the existing Named Entity Recognition (NER) models have achieved promising performance, they suffer from certain drawbacks. The sequence labeling-based NER models do not perform well in recognizing long entities as they focus only on word-level information, while the segment-based NER models which focus on processing segment instead of single word are unable to capture the word-level dependencies within the segment. Moreover, as boundary detection and type prediction may cooperate with each other for the NER task, it is also important for the two sub-tasks to mutually reinforce each other by sharing their information. In this paper, we propose a novel Modularized Interaction Network (MIN) model which utilizes both segment-level information and word-level dependencies, and incorporates an interaction mechanism to support information sharing between boundary detection and type prediction to enhance the performance for the NER task. We have conducted extensive experiments based on three NER benchmark datasets. The performance results have shown that the proposed MIN model has outperformed the current state-of-the-art models.", "tokens": ["Although", "the", "existing", "Named", "Entity", "Recognition", "(", "NER", ")", "models", "have", "achieved", "promising", "performance", ",", "they", "suffer", "from", "certain", "drawbacks", ".", "The", "sequence", "labeling-based", "NER", "models", "do", "not", "perform", "well", "in", "recognizing", "long", "entities", "as", "they", "focus", "only", "on", "word-level", "information", ",", "while", "the", "segment-based", "NER", "models", "which", "focus", "on", "processing", "segment", "instead", "of", "single", "word", "are", "unable", "to", "capture", "the", "word-level", "dependencies", "within", "the", "segment", ".", "Moreover", ",", "as", "boundary", "detection", "and", "type", "prediction", "may", "cooperate", "with", "each", "other", "for", "the", "NER", "task", ",", "it", "is", "also", "important", "for", "the", "two", "sub-tasks", "to", "mutually", "reinforce", "each", "other", "by", "sharing", "their", "information", ".", "In", "this", "paper", ",", "we", "propose", "a", "novel", "Modularized", "Interaction", "Network", "(", "MIN", ")", "model", "which", "utilizes", "both", "segment-level", "information", "and", "word-level", "dependencies", ",", "and", "incorporates", "an", "interaction", "mechanism", "to", "support", "information", "sharing", "between", "boundary", "detection", "and", "type", "prediction", "to", "enhance", "the", "performance", "for", "the", "NER", "task", ".", "We", "have", "conducted", "extensive", "experiments", "based", "on", "three", "NER", "benchmark", "datasets", ".", "The", "performance", "results", "have", "shown", "that", "the", "proposed", "MIN", "model", "has", "outperformed", "the", "current", "state-of-the-art", "models", "."], "entities": [{"type": "Operation", "start": 111, "end": 118, "text": "Modularized Interaction Network (MIN) model", "sent_idx": 3}, {"type": "Effect", "start": 145, "end": 146, "text": "performance", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--17"}
{"text": "The Lottery Ticket Hypothesis suggests that an over-parametrized network consists of \u201dlottery tickets\u201d, and training a certain collection of them (i.e., a subnetwork) can match the performance of the full model. In this paper, we study such a collection of tickets, which is referred to as \u201dwinning tickets\u201d, in extremely over-parametrized models, e.g., pre-trained language models. We observe that at certain compression ratios, the generalization performance of the winning tickets can not only match but also exceed that of the full model. In particular, we observe a phase transition phenomenon: As the compression ratio increases, generalization performance of the winning tickets first improves then deteriorates after a certain threshold. We refer to the tickets on the threshold as \u201dsuper tickets\u201d. We further show that the phase transition is task and model dependent \u2014 as the model size becomes larger and the training data set becomes smaller, the transition becomes more pronounced. Our experiments on the GLUE benchmark show that the super tickets improve single task fine-tuning by 0.9 points on BERT-base and 1.0 points on BERT-large, in terms of task-average score. We also demonstrate that adaptively sharing the super tickets across tasks benefits multi-task learning.", "tokens": ["The", "Lottery", "Ticket", "Hypothesis", "suggests", "that", "an", "over-parametrized", "network", "consists", "of", "\u201d", "lottery", "tickets", "\u201d", ",", "and", "training", "a", "certain", "collection", "of", "them", "(", "i.e.", ",", "a", "subnetwork", ")", "can", "match", "the", "performance", "of", "the", "full", "model", ".", "In", "this", "paper", ",", "we", "study", "such", "a", "collection", "of", "tickets", ",", "which", "is", "referred", "to", "as", "\u201d", "winning", "tickets", "\u201d", ",", "in", "extremely", "over-parametrized", "models", ",", "e.g.", ",", "pre-trained", "language", "models", ".", "We", "observe", "that", "at", "certain", "compression", "ratios", ",", "the", "generalization", "performance", "of", "the", "winning", "tickets", "can", "not", "only", "match", "but", "also", "exceed", "that", "of", "the", "full", "model", ".", "In", "particular", ",", "we", "observe", "a", "phase", "transition", "phenomenon", ":", "As", "the", "compression", "ratio", "increases", ",", "generalization", "performance", "of", "the", "winning", "tickets", "first", "improves", "then", "deteriorates", "after", "a", "certain", "threshold", ".", "We", "refer", "to", "the", "tickets", "on", "the", "threshold", "as", "\u201d", "super", "tickets", "\u201d", ".", "We", "further", "show", "that", "the", "phase", "transition", "is", "task", "and", "model", "dependent", "\u2014", "as", "the", "model", "size", "becomes", "larger", "and", "the", "training", "data", "set", "becomes", "smaller", ",", "the", "transition", "becomes", "more", "pronounced", ".", "Our", "experiments", "on", "the", "GLUE", "benchmark", "show", "that", "the", "super", "tickets", "improve", "single", "task", "fine-tuning", "by", "0.9", "points", "on", "BERT-base", "and", "1.0", "points", "on", "BERT-large", ",", "in", "terms", "of", "task-average", "score", ".", "We", "also", "demonstrate", "that", "adaptively", "sharing", "the", "super", "tickets", "across", "tasks", "benefits", "multi-task", "learning", "."], "entities": [{"type": "Operation", "start": 186, "end": 188, "text": "super tickets", "sent_idx": 6}, {"type": "Effect", "start": 206, "end": 208, "text": "task-average score", "sent_idx": 6}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--510"}
{"text": "This work presents Keep it Simple (KiS), a new approach to unsupervised text simplification which learns to balance a reward across three properties: fluency, salience and simplicity. We train the model with a novel algorithm to optimize the reward (k-SCST), in which the model proposes several candidate simplifications, computes each candidate\u2019s reward, and encourages candidates that outperform the mean reward. Finally, we propose a realistic text comprehension task as an evaluation method for text simplification. When tested on the English news domain, the KiS model outperforms strong supervised baselines by more than 4 SARI points, and can help people complete a comprehension task an average of 18% faster while retaining accuracy, when compared to the original text.", "tokens": ["This", "work", "presents", "Keep", "it", "Simple", "(", "KiS", ")", ",", "a", "new", "approach", "to", "unsupervised", "text", "simplification", "which", "learns", "to", "balance", "a", "reward", "across", "three", "properties", ":", "fluency", ",", "salience", "and", "simplicity", ".", "We", "train", "the", "model", "with", "a", "novel", "algorithm", "to", "optimize", "the", "reward", "(", "k-SCST", ")", ",", "in", "which", "the", "model", "proposes", "several", "candidate", "simplifications", ",", "computes", "each", "candidate", "\u2019s", "reward", ",", "and", "encourages", "candidates", "that", "outperform", "the", "mean", "reward", ".", "Finally", ",", "we", "propose", "a", "realistic", "text", "comprehension", "task", "as", "an", "evaluation", "method", "for", "text", "simplification", ".", "When", "tested", "on", "the", "English", "news", "domain", ",", "the", "KiS", "model", "outperforms", "strong", "supervised", "baselines", "by", "more", "than", "4", "SARI", "points", ",", "and", "can", "help", "people", "complete", "a", "comprehension", "task", "an", "average", "of", "18", "%", "faster", "while", "retaining", "accuracy", ",", "when", "compared", "to", "the", "original", "text", "."], "entities": [{"type": "Operation", "start": 99, "end": 101, "text": "KiS model", "sent_idx": 3}, {"type": "Effect", "start": 109, "end": 111, "text": "SARI points", "sent_idx": 3}, {"type": "Effect", "start": 128, "end": 129, "text": "accuracy", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}], "id": "abstract-2021--acl-long--498"}
{"text": "This paper addresses a data-driven surface realisation model based on a large-scale reversible grammar of German. We investigate the relationship between the surface realisation performance and the character of the input to generation, i.e. its degree of underspecification. We extend a syntactic surface realisation system, which can be trained to choose among word order variants, such that the candidate set includes active and passive variants. This allows us to study the interaction of voice and word order alternations in realistic German corpus data. We show that with an appropriately underspecified input, a linguistically informed realisation model trained to regenerate strings from the underlying semantic representation achieves 91.5% accuracy (over a baseline of 82.5%) in the prediction of the original voice.", "tokens": ["This", "paper", "addresses", "a", "data-driven", "surface", "realisation", "model", "based", "on", "a", "large-scale", "reversible", "grammar", "of", "German", ".", "We", "investigate", "the", "relationship", "between", "the", "surface", "realisation", "performance", "and", "the", "character", "of", "the", "input", "to", "generation", ",", "i.e.", "its", "degree", "of", "underspecification", ".", "We", "extend", "a", "syntactic", "surface", "realisation", "system", ",", "which", "can", "be", "trained", "to", "choose", "among", "word", "order", "variants", ",", "such", "that", "the", "candidate", "set", "includes", "active", "and", "passive", "variants", ".", "This", "allows", "us", "to", "study", "the", "interaction", "of", "voice", "and", "word", "order", "alternations", "in", "realistic", "German", "corpus", "data", ".", "We", "show", "that", "with", "an", "appropriately", "underspecified", "input", ",", "a", "linguistically", "informed", "realisation", "model", "trained", "to", "regenerate", "strings", "from", "the", "underlying", "semantic", "representation", "achieves", "91.5", "%", "accuracy", "(", "over", "a", "baseline", "of", "82.5", "%", ")", "in", "the", "prediction", "of", "the", "original", "voice", "."], "entities": [{"type": "Operation", "start": 100, "end": 104, "text": "linguistically informed realisation model", "sent_idx": 4}, {"type": "Effect", "start": 116, "end": 117, "text": "accuracy", "sent_idx": 4}], "relations": [{"type": "Affect", "head": 0, "tail": 1}], "id": "P11-1101"}
{"text": "Current event-centric knowledge graphs highly rely on explicit connectives to mine relations between events. Unfortunately, due to the sparsity of connectives, these methods severely undermine the coverage of EventKGs. The lack of high-quality labelled corpora further exacerbates that problem. In this paper, we propose a knowledge projection paradigm for event relation extraction: projecting discourse knowledge to narratives by exploiting the commonalities between them. Specifically, we propose Multi-tier Knowledge Projection Network (MKPNet), which can leverage multi-tier discourse knowledge effectively for event relation extraction. In this way, the labelled data requirement is significantly reduced, and implicit event relations can be effectively extracted. Intrinsic experimental results show that MKPNet achieves the new state-of-the-art performance and extrinsic experimental results verify the value of the extracted event relations.", "tokens": ["Current", "event-centric", "knowledge", "graphs", "highly", "rely", "on", "explicit", "connectives", "to", "mine", "relations", "between", "events", ".", "Unfortunately", ",", "due", "to", "the", "sparsity", "of", "connectives", ",", "these", "methods", "severely", "undermine", "the", "coverage", "of", "EventKGs", ".", "The", "lack", "of", "high-quality", "labelled", "corpora", "further", "exacerbates", "that", "problem", ".", "In", "this", "paper", ",", "we", "propose", "a", "knowledge", "projection", "paradigm", "for", "event", "relation", "extraction", ":", "projecting", "discourse", "knowledge", "to", "narratives", "by", "exploiting", "the", "commonalities", "between", "them", ".", "Specifically", ",", "we", "propose", "Multi-tier", "Knowledge", "Projection", "Network", "(", "MKPNet", ")", ",", "which", "can", "leverage", "multi-tier", "discourse", "knowledge", "effectively", "for", "event", "relation", "extraction", ".", "In", "this", "way", ",", "the", "labelled", "data", "requirement", "is", "significantly", "reduced", ",", "and", "implicit", "event", "relations", "can", "be", "effectively", "extracted", ".", "Intrinsic", "experimental", "results", "show", "that", "MKPNet", "achieves", "the", "new", "state-of-the-art", "performance", "and", "extrinsic", "experimental", "results", "verify", "the", "value", "of", "the", "extracted", "event", "relations", "."], "entities": [{"type": "Operation", "start": 121, "end": 122, "text": "MKPNet", "sent_idx": 6}, {"type": "Effect", "start": 126, "end": 127, "text": "performance", "sent_idx": 6}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--60"}
{"text": "Extensive knowledge bases of entailment rules between predicates are crucial for applied semantic inference. In this paper we propose an algorithm that utilizes transitivity constraints to learn a globally-optimal set of entailment rules for typed predicates. We model the task as a graph learning problem and suggest methods that scale the algorithm to larger graphs. We apply the algorithm over a large data set of extracted predicate instances, from which a resource of typed entailment rules has been recently released (Schoenmackers et al., 2010). Our results show that using global transitivity information substantially improves performance over this resource and several baselines, and that our scaling methods allow us to increase the scope of global learning of entailment-rule graphs.", "tokens": ["Extensive", "knowledge", "bases", "of", "entailment", "rules", "between", "predicates", "are", "crucial", "for", "applied", "semantic", "inference", ".", "In", "this", "paper", "we", "propose", "an", "algorithm", "that", "utilizes", "transitivity", "constraints", "to", "learn", "a", "globally-optimal", "set", "of", "entailment", "rules", "for", "typed", "predicates", ".", "We", "model", "the", "task", "as", "a", "graph", "learning", "problem", "and", "suggest", "methods", "that", "scale", "the", "algorithm", "to", "larger", "graphs", ".", "We", "apply", "the", "algorithm", "over", "a", "large", "data", "set", "of", "extracted", "predicate", "instances", ",", "from", "which", "a", "resource", "of", "typed", "entailment", "rules", "has", "been", "recently", "released", "(", "Schoenmackers", "et", "al.", ",", "2010", ")", ".", "Our", "results", "show", "that", "using", "global", "transitivity", "information", "substantially", "improves", "performance", "over", "this", "resource", "and", "several", "baselines", ",", "and", "that", "our", "scaling", "methods", "allow", "us", "to", "increase", "the", "scope", "of", "global", "learning", "of", "entailment-rule", "graphs", "."], "entities": [{"type": "Operation", "start": 96, "end": 100, "text": "using global transitivity information", "sent_idx": 4}, {"type": "Effect", "start": 102, "end": 103, "text": "performance", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "P11-1062"}
{"text": "While traditional systems for Open Information Extraction were statistical and rule-based, recently neural models have been introduced for the task. Our work builds upon CopyAttention, a sequence generation OpenIE model (Cui et. al. 18). Our analysis reveals that CopyAttention produces a constant number of extractions per sentence, and its extracted tuples often express redundant information. We present IMoJIE, an extension to CopyAttention, which produces the next extraction conditioned on all previously extracted tuples. This approach overcomes both shortcomings of CopyAttention, resulting in a variable number of diverse extractions per sentence. We train IMoJIE on training data bootstrapped from extractions of several non-neural systems, which have been automatically filtered to reduce redundancy and noise. IMoJIE outperforms CopyAttention by about 18 F1 pts, and a BERT-based strong baseline by 2 F1 pts, establishing a new state of the art for the task.", "tokens": ["While", "traditional", "systems", "for", "Open", "Information", "Extraction", "were", "statistical", "and", "rule-based", ",", "recently", "neural", "models", "have", "been", "introduced", "for", "the", "task", ".", "Our", "work", "builds", "upon", "CopyAttention", ",", "a", "sequence", "generation", "OpenIE", "model", "(", "Cui", "et", ".", "al.", "18", ")", ".", "Our", "analysis", "reveals", "that", "CopyAttention", "produces", "a", "constant", "number", "of", "extractions", "per", "sentence", ",", "and", "its", "extracted", "tuples", "often", "express", "redundant", "information", ".", "We", "present", "IMoJIE", ",", "an", "extension", "to", "CopyAttention", ",", "which", "produces", "the", "next", "extraction", "conditioned", "on", "all", "previously", "extracted", "tuples", ".", "This", "approach", "overcomes", "both", "shortcomings", "of", "CopyAttention", ",", "resulting", "in", "a", "variable", "number", "of", "diverse", "extractions", "per", "sentence", ".", "We", "train", "IMoJIE", "on", "training", "data", "bootstrapped", "from", "extractions", "of", "several", "non-neural", "systems", ",", "which", "have", "been", "automatically", "filtered", "to", "reduce", "redundancy", "and", "noise", ".", "IMoJIE", "outperforms", "CopyAttention", "by", "about", "18", "F1", "pts", ",", "and", "a", "BERT-based", "strong", "baseline", "by", "2", "F1", "pts", ",", "establishing", "a", "new", "state", "of", "the", "art", "for", "the", "task", "."], "entities": [{"type": "Operation", "start": 129, "end": 130, "text": "IMoJIE", "sent_idx": 6}, {"type": "Effect", "start": 145, "end": 146, "text": "F1", "sent_idx": 6}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--521"}
{"text": "Previous works that integrated news articles to better process stock prices used a variety of neural networks to predict price movements. The textual and price information were both encoded in the neural network, and it is therefore difficult to apply this approach in situations other than the original framework of the notoriously hard problem of price prediction. In contrast, this paper presents a method to encode the influence of news articles through a vector representation of stocks called a  stock embedding . The stock embedding is acquired with a deep learning framework using both news articles and price history. Because the embedding takes the operational form of a vector, it is applicable to other financial problems besides price prediction. As one example application, we show the results of portfolio optimization using Reuters & Bloomberg headlines, producing a capital gain 2.8 times larger than that obtained with a baseline method using only stock price data. This suggests that the proposed stock embedding can leverage textual financial semantics to solve financial prediction problems.", "tokens": ["Previous", "works", "that", "integrated", "news", "articles", "to", "better", "process", "stock", "prices", "used", "a", "variety", "of", "neural", "networks", "to", "predict", "price", "movements", ".", "The", "textual", "and", "price", "information", "were", "both", "encoded", "in", "the", "neural", "network", ",", "and", "it", "is", "therefore", "difficult", "to", "apply", "this", "approach", "in", "situations", "other", "than", "the", "original", "framework", "of", "the", "notoriously", "hard", "problem", "of", "price", "prediction", ".", "In", "contrast", ",", "this", "paper", "presents", "a", "method", "to", "encode", "the", "influence", "of", "news", "articles", "through", "a", "vector", "representation", "of", "stocks", "called", "a", " ", "stock", "embedding", ".", "The", "stock", "embedding", "is", "acquired", "with", "a", "deep", "learning", "framework", "using", "both", "news", "articles", "and", "price", "history", ".", "Because", "the", "embedding", "takes", "the", "operational", "form", "of", "a", "vector", ",", "it", "is", "applicable", "to", "other", "financial", "problems", "besides", "price", "prediction", ".", "As", "one", "example", "application", ",", "we", "show", "the", "results", "of", "portfolio", "optimization", "using", "Reuters", "&", "Bloomberg", "headlines", ",", "producing", "a", "capital", "gain", "2.8", "times", "larger", "than", "that", "obtained", "with", "a", "baseline", "method", "using", "only", "stock", "price", "data", ".", "This", "suggests", "that", "the", "proposed", "stock", "embedding", "can", "leverage", "textual", "financial", "semantics", "to", "solve", "financial", "prediction", "problems", "."], "entities": [{"type": "Operation", "start": 69, "end": 81, "text": "encode the influence of news articles through a vector representation of stocks", "sent_idx": 2}, {"type": "Effect", "start": 147, "end": 149, "text": "capital gain", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--307"}
{"text": "This paper presents a novel approach to automatic captioning of geo-tagged images by summarizing multiple web-documents that contain information related to an image's location. The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. Summaries generated using dependency patterns also lead to more readable summaries than those generated without dependency patterns.", "tokens": ["This", "paper", "presents", "a", "novel", "approach", "to", "automatic", "captioning", "of", "geo-tagged", "images", "by", "summarizing", "multiple", "web-documents", "that", "contain", "information", "related", "to", "an", "image", "'s", "location", ".", "The", "summarizer", "is", "biased", "by", "dependency", "pattern", "models", "towards", "sentences", "which", "contain", "features", "typically", "provided", "for", "different", "scene", "types", "such", "as", "those", "of", "churches", ",", "bridges", ",", "etc", ".", "Our", "results", "show", "that", "summaries", "biased", "by", "dependency", "pattern", "models", "lead", "to", "significantly", "higher", "ROUGE", "scores", "than", "both", "n-gram", "language", "models", "reported", "in", "previous", "work", "and", "also", "Wikipedia", "baseline", "summaries", ".", "Summaries", "generated", "using", "dependency", "patterns", "also", "lead", "to", "more", "readable", "summaries", "than", "those", "generated", "without", "dependency", "patterns", "."], "entities": [{"type": "Operation", "start": 62, "end": 65, "text": "dependency pattern models", "sent_idx": 2}, {"type": "Effect", "start": 69, "end": 71, "text": "ROUGE scores", "sent_idx": 2}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "P10-1127"}
{"text": "We present a novel method for record extraction from social streams such as Twitter. Unlike typical extraction setups, these environments are characterized by short, one sentence messages with heavily colloquial speech. To further complicate matters, individual messages may not express the full relation to be uncovered, as is often assumed in extraction tasks. We develop a graphical model that addresses these problems by learning a latent set of records and a record-message alignment simultaneously; the output of our model is a set of canonical records, the values of which are consistent with aligned messages. We demonstrate that our approach is able to accurately induce event records from Twitter messages, evaluated against events from a local city guide. Our method achieves significant error reduction over baseline methods.", "tokens": ["We", "present", "a", "novel", "method", "for", "record", "extraction", "from", "social", "streams", "such", "as", "Twitter", ".", "Unlike", "typical", "extraction", "setups", ",", "these", "environments", "are", "characterized", "by", "short", ",", "one", "sentence", "messages", "with", "heavily", "colloquial", "speech", ".", "To", "further", "complicate", "matters", ",", "individual", "messages", "may", "not", "express", "the", "full", "relation", "to", "be", "uncovered", ",", "as", "is", "often", "assumed", "in", "extraction", "tasks", ".", "We", "develop", "a", "graphical", "model", "that", "addresses", "these", "problems", "by", "learning", "a", "latent", "set", "of", "records", "and", "a", "record-message", "alignment", "simultaneously", ";", "the", "output", "of", "our", "model", "is", "a", "set", "of", "canonical", "records", ",", "the", "values", "of", "which", "are", "consistent", "with", "aligned", "messages", ".", "We", "demonstrate", "that", "our", "approach", "is", "able", "to", "accurately", "induce", "event", "records", "from", "Twitter", "messages", ",", "evaluated", "against", "events", "from", "a", "local", "city", "guide", ".", "Our", "method", "achieves", "significant", "error", "reduction", "over", "baseline", "methods", "."], "entities": [{"type": "Operation", "start": 63, "end": 65, "text": "graphical model", "sent_idx": 3}, {"type": "Effect", "start": 133, "end": 134, "text": "error", "sent_idx": 5}], "relations": [{"type": "Neg_Affect", "head": 0, "tail": 1}], "id": "P11-1040"}
{"text": "Knowledge graph (KG) representation learning techniques that learn continuous embeddings of entities and relations in the KG have become popular in many AI applications. With a large KG, the embeddings consume a large amount of storage and memory. This is problematic and prohibits the deployment of these techniques in many real world settings. Thus, we propose an approach that compresses the KG embedding layer by representing each entity in the KG as a vector of discrete codes and then composes the embeddings from these codes. The approach can be trained end-to-end with simple modifications to any existing KG embedding technique. We evaluate the approach on various standard KG embedding evaluations and show that it achieves 50-1000x compression of embeddings with a minor loss in performance. The compressed embeddings also retain the ability to perform various reasoning tasks such as KG inference.", "tokens": ["Knowledge", "graph", "(", "KG", ")", "representation", "learning", "techniques", "that", "learn", "continuous", "embeddings", "of", "entities", "and", "relations", "in", "the", "KG", "have", "become", "popular", "in", "many", "AI", "applications", ".", "With", "a", "large", "KG", ",", "the", "embeddings", "consume", "a", "large", "amount", "of", "storage", "and", "memory", ".", "This", "is", "problematic", "and", "prohibits", "the", "deployment", "of", "these", "techniques", "in", "many", "real", "world", "settings", ".", "Thus", ",", "we", "propose", "an", "approach", "that", "compresses", "the", "KG", "embedding", "layer", "by", "representing", "each", "entity", "in", "the", "KG", "as", "a", "vector", "of", "discrete", "codes", "and", "then", "composes", "the", "embeddings", "from", "these", "codes", ".", "The", "approach", "can", "be", "trained", "end-to-end", "with", "simple", "modifications", "to", "any", "existing", "KG", "embedding", "technique", ".", "We", "evaluate", "the", "approach", "on", "various", "standard", "KG", "embedding", "evaluations", "and", "show", "that", "it", "achieves", "50", "-", "1000x", "compression", "of", "embeddings", "with", "a", "minor", "loss", "in", "performance", ".", "The", "compressed", "embeddings", "also", "retain", "the", "ability", "to", "perform", "various", "reasoning", "tasks", "such", "as", "KG", "inference", "."], "entities": [{"type": "Operation", "start": 66, "end": 71, "text": "compresses the KG embedding layer", "sent_idx": 3}, {"type": "Effect", "start": 127, "end": 130, "text": "compression of embeddings", "sent_idx": 5}, {"type": "Effect", "start": 135, "end": 136, "text": "performance", "sent_idx": 5}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}], "id": "abstract-2020--acl-main--238"}
{"text": "Logical table-to-text generation aims to automatically generate fluent and logically faithful text from tables. The task remains challenging where deep learning models often generated linguistically fluent but logically inconsistent text. The underlying reason may be that deep learning models often capture surface-level spurious correlations rather than the causal relationships between the table x and the sentence y . Specifically, in the training stage, a model can get a low empirical loss without understanding x and use spurious statistical cues instead. In this paper, we propose a de-confounded variational encoder-decoder (DCVED) based on causal intervention, learning the objective p( y | do ( x )) . Firstly, we propose to use variational inference to estimate the confounders in the latent space and cooperate with the causal intervention based on Pearl\u2019s do-calculus to alleviate the spurious correlations. Secondly, to make the latent confounder meaningful, we propose a back-prediction process to predict the not-used entities but linguistically similar to the exactly selected ones. Finally, since our variational model can generate multiple candidates, we train a table-text selector to find out the best candidate sentence for the given table. An extensive set of experiments show that our model outperforms the baselines and achieves new state-of-the-art performance on two logical table-to-text datasets in terms of logical fidelity.", "tokens": ["Logical", "table-to-text", "generation", "aims", "to", "automatically", "generate", "fluent", "and", "logically", "faithful", "text", "from", "tables", ".", "The", "task", "remains", "challenging", "where", "deep", "learning", "models", "often", "generated", "linguistically", "fluent", "but", "logically", "inconsistent", "text", ".", "The", "underlying", "reason", "may", "be", "that", "deep", "learning", "models", "often", "capture", "surface-level", "spurious", "correlations", "rather", "than", "the", "causal", "relationships", "between", "the", "table", "x", "and", "the", "sentence", "y", ".", "Specifically", ",", "in", "the", "training", "stage", ",", "a", "model", "can", "get", "a", "low", "empirical", "loss", "without", "understanding", "x", "and", "use", "spurious", "statistical", "cues", "instead", ".", "In", "this", "paper", ",", "we", "propose", "a", "de-confounded", "variational", "encoder-decoder", "(", "DCVED", ")", "based", "on", "causal", "intervention", ",", "learning", "the", "objective", "p", "(", "y", "|", "do", "(", "x", ")", ")", ".", "Firstly", ",", "we", "propose", "to", "use", "variational", "inference", "to", "estimate", "the", "confounders", "in", "the", "latent", "space", "and", "cooperate", "with", "the", "causal", "intervention", "based", "on", "Pearl", "\u2019s", "do-calculus", "to", "alleviate", "the", "spurious", "correlations", ".", "Secondly", ",", "to", "make", "the", "latent", "confounder", "meaningful", ",", "we", "propose", "a", "back-prediction", "process", "to", "predict", "the", "not-used", "entities", "but", "linguistically", "similar", "to", "the", "exactly", "selected", "ones", ".", "Finally", ",", "since", "our", "variational", "model", "can", "generate", "multiple", "candidates", ",", "we", "train", "a", "table-text", "selector", "to", "find", "out", "the", "best", "candidate", "sentence", "for", "the", "given", "table", ".", "An", "extensive", "set", "of", "experiments", "show", "that", "our", "model", "outperforms", "the", "baselines", "and", "achieves", "new", "state-of-the-art", "performance", "on", "two", "logical", "table-to-text", "datasets", "in", "terms", "of", "logical", "fidelity", "."], "entities": [{"type": "Operation", "start": 92, "end": 98, "text": "de-confounded variational encoder-decoder (DCVED)", "sent_idx": 4}, {"type": "Effect", "start": 221, "end": 222, "text": "performance", "sent_idx": 8}, {"type": "Effect", "start": 231, "end": 232, "text": "fidelity", "sent_idx": 8}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}], "id": "abstract-2021--acl-long--430"}
{"text": "The Surface Realization Shared Tasks of 2018 and 2019 were Natural Language Generation shared tasks with the goal of exploring approaches to surface realization from Universal-Dependency-like trees to surface strings for several languages. In the 2018 shared task there was very little difference in the absolute performance of systems trained with and without additional, synthetically created data, and a new rule prohibiting the use of synthetic data was introduced for the 2019 shared task. Contrary to the findings of the 2018 shared task, we show, in experiments on the English 2018 dataset, that the use of synthetic data can have a substantial positive effect \u2013 an improvement of almost 8 BLEU points for a previously state-of-the-art system. We analyse the effects of synthetic data, and we argue that its use should be encouraged rather than prohibited so that future research efforts continue to explore systems that can take advantage of such data.", "tokens": ["The", "Surface", "Realization", "Shared", "Tasks", "of", "2018", "and", "2019", "were", "Natural", "Language", "Generation", "shared", "tasks", "with", "the", "goal", "of", "exploring", "approaches", "to", "surface", "realization", "from", "Universal-Dependency-like", "trees", "to", "surface", "strings", "for", "several", "languages", ".", "In", "the", "2018", "shared", "task", "there", "was", "very", "little", "difference", "in", "the", "absolute", "performance", "of", "systems", "trained", "with", "and", "without", "additional", ",", "synthetically", "created", "data", ",", "and", "a", "new", "rule", "prohibiting", "the", "use", "of", "synthetic", "data", "was", "introduced", "for", "the", "2019", "shared", "task", ".", "Contrary", "to", "the", "findings", "of", "the", "2018", "shared", "task", ",", "we", "show", ",", "in", "experiments", "on", "the", "English", "2018", "dataset", ",", "that", "the", "use", "of", "synthetic", "data", "can", "have", "a", "substantial", "positive", "effect", "\u2013", "an", "improvement", "of", "almost", "8", "BLEU", "points", "for", "a", "previously", "state-of-the-art", "system", ".", "We", "analyse", "the", "effects", "of", "synthetic", "data", ",", "and", "we", "argue", "that", "its", "use", "should", "be", "encouraged", "rather", "than", "prohibited", "so", "that", "future", "research", "efforts", "continue", "to", "explore", "systems", "that", "can", "take", "advantage", "of", "such", "data", "."], "entities": [{"type": "Operation", "start": 101, "end": 105, "text": "use of synthetic data", "sent_idx": 2}, {"type": "Effect", "start": 117, "end": 119, "text": "BLEU points", "sent_idx": 2}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--665"}
{"text": "In this paper, we propose a new adversarial augmentation method for Neural Machine Translation (NMT). The main idea is to minimize the vicinal risk over virtual sentences sampled from two vicinity distributions, in which the crucial one is a novel vicinity distribution for adversarial sentences that describes a smooth interpolated embedding space centered around observed training sentence pairs. We then discuss our approach, AdvAug, to train NMT models using the embeddings of virtual sentences in sequence-to-sequence learning. Experiments on Chinese-English, English-French, and English-German translation benchmarks show that AdvAug achieves significant improvements over theTransformer (up to 4.9 BLEU points), and substantially outperforms other data augmentation techniques (e.g.back-translation) without using extra corpora.", "tokens": ["In", "this", "paper", ",", "we", "propose", "a", "new", "adversarial", "augmentation", "method", "for", "Neural", "Machine", "Translation", "(", "NMT", ")", ".", "The", "main", "idea", "is", "to", "minimize", "the", "vicinal", "risk", "over", "virtual", "sentences", "sampled", "from", "two", "vicinity", "distributions", ",", "in", "which", "the", "crucial", "one", "is", "a", "novel", "vicinity", "distribution", "for", "adversarial", "sentences", "that", "describes", "a", "smooth", "interpolated", "embedding", "space", "centered", "around", "observed", "training", "sentence", "pairs", ".", "We", "then", "discuss", "our", "approach", ",", "AdvAug", ",", "to", "train", "NMT", "models", "using", "the", "embeddings", "of", "virtual", "sentences", "in", "sequence-to-sequence", "learning", ".", "Experiments", "on", "Chinese-English", ",", "English-French", ",", "and", "English-German", "translation", "benchmarks", "show", "that", "AdvAug", "achieves", "significant", "improvements", "over", "theTransformer", "(", "up", "to", "4.9", "BLEU", "points", ")", ",", "and", "substantially", "outperforms", "other", "data", "augmentation", "techniques", "(", "e.g.back-translation", ")", "without", "using", "extra", "corpora", "."], "entities": [{"type": "Operation", "start": 98, "end": 99, "text": "AdvAug", "sent_idx": 3}, {"type": "Effect", "start": 108, "end": 110, "text": "BLEU points", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--529"}
{"text": "Backdoor attacks are a kind of insidious security threat against machine learning models. After being injected with a backdoor in training, the victim model will produce adversary-specified outputs on the inputs embedded with predesigned triggers but behave properly on normal inputs during inference. As a sort of emergent attack, backdoor attacks in natural language processing (NLP) are investigated insufficiently. As far as we know, almost all existing textual backdoor attack methods insert additional contents into normal samples as triggers, which causes the trigger-embedded samples to be detected and the backdoor attacks to be blocked without much effort. In this paper, we propose to use the syntactic structure as the trigger in textual backdoor attacks. We conduct extensive experiments to demonstrate that the syntactic trigger-based attack method can achieve comparable attack performance (almost 100% success rate) to the insertion-based methods but possesses much higher invisibility and stronger resistance to defenses. These results also reveal the significant insidiousness and harmfulness of textual backdoor attacks. All the code and data of this paper can be obtained at https://github.com/thunlp/HiddenKiller.", "tokens": ["Backdoor", "attacks", "are", "a", "kind", "of", "insidious", "security", "threat", "against", "machine", "learning", "models", ".", "After", "being", "injected", "with", "a", "backdoor", "in", "training", ",", "the", "victim", "model", "will", "produce", "adversary-specified", "outputs", "on", "the", "inputs", "embedded", "with", "predesigned", "triggers", "but", "behave", "properly", "on", "normal", "inputs", "during", "inference", ".", "As", "a", "sort", "of", "emergent", "attack", ",", "backdoor", "attacks", "in", "natural", "language", "processing", "(", "NLP", ")", "are", "investigated", "insufficiently", ".", "As", "far", "as", "we", "know", ",", "almost", "all", "existing", "textual", "backdoor", "attack", "methods", "insert", "additional", "contents", "into", "normal", "samples", "as", "triggers", ",", "which", "causes", "the", "trigger-embedded", "samples", "to", "be", "detected", "and", "the", "backdoor", "attacks", "to", "be", "blocked", "without", "much", "effort", ".", "In", "this", "paper", ",", "we", "propose", "to", "use", "the", "syntactic", "structure", "as", "the", "trigger", "in", "textual", "backdoor", "attacks", ".", "We", "conduct", "extensive", "experiments", "to", "demonstrate", "that", "the", "syntactic", "trigger-based", "attack", "method", "can", "achieve", "comparable", "attack", "performance", "(", "almost", "100", "%", "success", "rate", ")", "to", "the", "insertion-based", "methods", "but", "possesses", "much", "higher", "invisibility", "and", "stronger", "resistance", "to", "defenses", ".", "These", "results", "also", "reveal", "the", "significant", "insidiousness", "and", "harmfulness", "of", "textual", "backdoor", "attacks", ".", "All", "the", "code", "and", "data", "of", "this", "paper", "can", "be", "obtained", "at", "https://github.com/thunlp/HiddenKiller", "."], "entities": [{"type": "Operation", "start": 134, "end": 138, "text": "syntactic trigger-based attack method", "sent_idx": 5}, {"type": "Effect", "start": 147, "end": 149, "text": "success rate", "sent_idx": 5}, {"type": "Effect", "start": 142, "end": 143, "text": "performance", "sent_idx": 5}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}], "id": "abstract-2021--acl-long--37"}
{"text": "Recent work on bilingual Word Sense Disambiguation (WSD) has shown that a resource deprived language (L1) can benefit from the annotation work done in a resource rich language (L2) via parameter projection. However, this method assumes the presence of sufficient annotated data in one resource rich language which may not always be possible. Instead, we focus on the situation where there are two resource deprived languages, both having a very small amount of seed annotated data and a large amount of untagged data. We then use bilingual bootstrapping, wherein, a model trained using the seed annotated data of L1 is used to annotate the untagged data of L2 and vice versa using parameter projection. The untagged instances of L1 and L2 which get annotated with high confidence are then added to the seed data of the respective languages and the above process is repeated. Our experiments show that such a bilingual bootstrapping algorithm when evaluated on two different domains with small seed sizes using Hindi (L1) and Marathi (L2) as the language pair performs better than monolingual bootstrapping and significantly reduces annotation cost.", "tokens": ["Recent", "work", "on", "bilingual", "Word", "Sense", "Disambiguation", "(", "WSD", ")", "has", "shown", "that", "a", "resource", "deprived", "language", "(", "L1", ")", "can", "benefit", "from", "the", "annotation", "work", "done", "in", "a", "resource", "rich", "language", "(", "L2", ")", "via", "parameter", "projection", ".", "However", ",", "this", "method", "assumes", "the", "presence", "of", "sufficient", "annotated", "data", "in", "one", "resource", "rich", "language", "which", "may", "not", "always", "be", "possible", ".", "Instead", ",", "we", "focus", "on", "the", "situation", "where", "there", "are", "two", "resource", "deprived", "languages", ",", "both", "having", "a", "very", "small", "amount", "of", "seed", "annotated", "data", "and", "a", "large", "amount", "of", "untagged", "data", ".", "We", "then", "use", "bilingual", "bootstrapping", ",", "wherein", ",", "a", "model", "trained", "using", "the", "seed", "annotated", "data", "of", "L1", "is", "used", "to", "annotate", "the", "untagged", "data", "of", "L2", "and", "vice", "versa", "using", "parameter", "projection", ".", "The", "untagged", "instances", "of", "L1", "and", "L2", "which", "get", "annotated", "with", "high", "confidence", "are", "then", "added", "to", "the", "seed", "data", "of", "the", "respective", "languages", "and", "the", "above", "process", "is", "repeated", ".", "Our", "experiments", "show", "that", "such", "a", "bilingual", "bootstrapping", "algorithm", "when", "evaluated", "on", "two", "different", "domains", "with", "small", "seed", "sizes", "using", "Hindi", "(", "L1", ")", "and", "Marathi", "(", "L2", ")", "as", "the", "language", "pair", "performs", "better", "than", "monolingual", "bootstrapping", "and", "significantly", "reduces", "annotation", "cost", "."], "entities": [{"type": "Operation", "start": 166, "end": 169, "text": "bilingual bootstrapping algorithm", "sent_idx": 5}, {"type": "Effect", "start": 201, "end": 203, "text": "annotation cost", "sent_idx": 5}], "relations": [{"type": "Neg_Affect", "head": 0, "tail": 1}], "id": "P11-1057"}
{"text": "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.", "tokens": ["We", "present", "BART", ",", "a", "denoising", "autoencoder", "for", "pretraining", "sequence-to-sequence", "models", ".", "BART", "is", "trained", "by", "(", "1", ")", "corrupting", "text", "with", "an", "arbitrary", "noising", "function", ",", "and", "(", "2", ")", "learning", "a", "model", "to", "reconstruct", "the", "original", "text", ".", "It", "uses", "a", "standard", "Tranformer-based", "neural", "machine", "translation", "architecture", "which", ",", "despite", "its", "simplicity", ",", "can", "be", "seen", "as", "generalizing", "BERT", "(", "due", "to", "the", "bidirectional", "encoder", ")", ",", "GPT", "(", "with", "the", "left-to-right", "decoder", ")", ",", "and", "other", "recent", "pretraining", "schemes", ".", "We", "evaluate", "a", "number", "of", "noising", "approaches", ",", "finding", "the", "best", "performance", "by", "both", "randomly", "shuffling", "the", "order", "of", "sentences", "and", "using", "a", "novel", "in-filling", "scheme", ",", "where", "spans", "of", "text", "are", "replaced", "with", "a", "single", "mask", "token", ".", "BART", "is", "particularly", "effective", "when", "fine", "tuned", "for", "text", "generation", "but", "also", "works", "well", "for", "comprehension", "tasks", ".", "It", "matches", "the", "performance", "of", "RoBERTa", "on", "GLUE", "and", "SQuAD", ",", "and", "achieves", "new", "state-of-the-art", "results", "on", "a", "range", "of", "abstractive", "dialogue", ",", "question", "answering", ",", "and", "summarization", "tasks", ",", "with", "gains", "of", "up", "to", "3.5", "ROUGE", ".", "BART", "also", "provides", "a", "1.1", "BLEU", "increase", "over", "a", "back-translation", "system", "for", "machine", "translation", ",", "with", "only", "target", "language", "pretraining", ".", "We", "also", "replicate", "other", "pretraining", "schemes", "within", "the", "BART", "framework", ",", "to", "understand", "their", "effect", "on", "end-task", "performance", "."], "entities": [{"type": "Operation", "start": 178, "end": 179, "text": "BART", "sent_idx": 6}, {"type": "Effect", "start": 183, "end": 184, "text": "BLEU", "sent_idx": 6}, {"type": "Operation", "start": 122, "end": 123, "text": "BART", "sent_idx": 4}, {"type": "Effect", "start": 176, "end": 177, "text": "ROUGE", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 2, "tail": 3}], "id": "abstract-2020--acl-main--703"}
{"text": "Topic models have been successfully applied to many document analysis tasks to discover topics embedded in text. However, existing topic models generally cannot capture the latent topical structures in documents. Since languages are intrinsically cohesive and coherent, modeling and discovering latent topical transition structures within documents would be beneficial for many text analysis tasks. \n \nIn this work, we propose a new topic model, Structural Topic Model, which simultaneously discovers topics and reveals the latent topical structures in text through explicitly modeling topical transitions with a latent first-order Markov chain. Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering.", "tokens": ["Topic", "models", "have", "been", "successfully", "applied", "to", "many", "document", "analysis", "tasks", "to", "discover", "topics", "embedded", "in", "text", ".", "However", ",", "existing", "topic", "models", "generally", "can", "not", "capture", "the", "latent", "topical", "structures", "in", "documents", ".", "Since", "languages", "are", "intrinsically", "cohesive", "and", "coherent", ",", "modeling", "and", "discovering", "latent", "topical", "transition", "structures", "within", "documents", "would", "be", "beneficial", "for", "many", "text", "analysis", "tasks", ".", "\n \n", "In", "this", "work", ",", "we", "propose", "a", "new", "topic", "model", ",", "Structural", "Topic", "Model", ",", "which", "simultaneously", "discovers", "topics", "and", "reveals", "the", "latent", "topical", "structures", "in", "text", "through", "explicitly", "modeling", "topical", "transitions", "with", "a", "latent", "first-order", "Markov", "chain", ".", "Experiment", "results", "show", "that", "the", "proposed", "Structural", "Topic", "Model", "can", "effectively", "discover", "topical", "structures", "in", "text", ",", "and", "the", "identified", "structures", "significantly", "improve", "the", "performance", "of", "tasks", "such", "as", "sentence", "annotation", "and", "sentence", "ordering", "."], "entities": [{"type": "Operation", "start": 112, "end": 116, "text": "topical structures in text", "sent_idx": 4}, {"type": "Effect", "start": 124, "end": 125, "text": "performance", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "P11-1153"}
{"text": "For task-oriented dialog systems to be maximally useful, it must be able to process conversations in a way that is (1) generalizable with a small number of training examples for new task domains, and (2) robust to user input in various styles, modalities, or domains. In pursuit of these goals, we introduce the RADDLE benchmark, a collection of corpora and tools for evaluating the performance of models across a diverse set of domains. By including tasks with limited training data, RADDLE is designed to favor and encourage models with a strong generalization ability. RADDLE also includes a diagnostic checklist that facilitates detailed robustness analysis in aspects such as language variations, speech errors, unseen entities, and out-of-domain utterances. We evaluate recent state-of-the-art systems based on pre-training and fine-tuning, and find that grounded pre-training on heterogeneous dialog corpora performs better than training a separate model per domain. Adversarial training is also proposed to improve model robustness against noisy inputs. Overall, existing models are less than satisfactory in robustness evaluation, which suggests opportunities for future improvement.", "tokens": ["For", "task-oriented", "dialog", "systems", "to", "be", "maximally", "useful", ",", "it", "must", "be", "able", "to", "process", "conversations", "in", "a", "way", "that", "is", "(", "1", ")", "generalizable", "with", "a", "small", "number", "of", "training", "examples", "for", "new", "task", "domains", ",", "and", "(", "2", ")", "robust", "to", "user", "input", "in", "various", "styles", ",", "modalities", ",", "or", "domains", ".", "In", "pursuit", "of", "these", "goals", ",", "we", "introduce", "the", "RADDLE", "benchmark", ",", "a", "collection", "of", "corpora", "and", "tools", "for", "evaluating", "the", "performance", "of", "models", "across", "a", "diverse", "set", "of", "domains", ".", "By", "including", "tasks", "with", "limited", "training", "data", ",", "RADDLE", "is", "designed", "to", "favor", "and", "encourage", "models", "with", "a", "strong", "generalization", "ability", ".", "RADDLE", "also", "includes", "a", "diagnostic", "checklist", "that", "facilitates", "detailed", "robustness", "analysis", "in", "aspects", "such", "as", "language", "variations", ",", "speech", "errors", ",", "unseen", "entities", ",", "and", "out-of-domain", "utterances", ".", "We", "evaluate", "recent", "state-of-the-art", "systems", "based", "on", "pre-training", "and", "fine-tuning", ",", "and", "find", "that", "grounded", "pre-training", "on", "heterogeneous", "dialog", "corpora", "performs", "better", "than", "training", "a", "separate", "model", "per", "domain", ".", "Adversarial", "training", "is", "also", "proposed", "to", "improve", "model", "robustness", "against", "noisy", "inputs", ".", "Overall", ",", "existing", "models", "are", "less", "than", "satisfactory", "in", "robustness", "evaluation", ",", "which", "suggests", "opportunities", "for", "future", "improvement", "."], "entities": [{"type": "Operation", "start": 165, "end": 167, "text": "Adversarial training", "sent_idx": 5}, {"type": "Effect", "start": 173, "end": 174, "text": "robustness", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--341"}
{"text": "Aspect-based Sentiment Analysis (ABSA) aims to identify the aspect terms, their corresponding sentiment polarities, and the opinion terms. There exist seven subtasks in ABSA. Most studies only focus on the subsets of these subtasks, which leads to various complicated ABSA models while hard to solve these subtasks in a unified framework. In this paper, we redefine every subtask target as a sequence mixed by pointer indexes and sentiment class indexes, which converts all ABSA subtasks into a unified generative formulation. Based on the unified formulation, we exploit the pre-training sequence-to-sequence model BART to solve all ABSA subtasks in an end-to-end framework. Extensive experiments on four ABSA datasets for seven subtasks demonstrate that our framework achieves substantial performance gain and provides a real unified end-to-end solution for the whole ABSA subtasks, which could benefit multiple tasks.", "tokens": ["Aspect-based", "Sentiment", "Analysis", "(", "ABSA", ")", "aims", "to", "identify", "the", "aspect", "terms", ",", "their", "corresponding", "sentiment", "polarities", ",", "and", "the", "opinion", "terms", ".", "There", "exist", "seven", "subtasks", "in", "ABSA", ".", "Most", "studies", "only", "focus", "on", "the", "subsets", "of", "these", "subtasks", ",", "which", "leads", "to", "various", "complicated", "ABSA", "models", "while", "hard", "to", "solve", "these", "subtasks", "in", "a", "unified", "framework", ".", "In", "this", "paper", ",", "we", "redefine", "every", "subtask", "target", "as", "a", "sequence", "mixed", "by", "pointer", "indexes", "and", "sentiment", "class", "indexes", ",", "which", "converts", "all", "ABSA", "subtasks", "into", "a", "unified", "generative", "formulation", ".", "Based", "on", "the", "unified", "formulation", ",", "we", "exploit", "the", "pre-training", "sequence-to-sequence", "model", "BART", "to", "solve", "all", "ABSA", "subtasks", "in", "an", "end-to-end", "framework", ".", "Extensive", "experiments", "on", "four", "ABSA", "datasets", "for", "seven", "subtasks", "demonstrate", "that", "our", "framework", "achieves", "substantial", "performance", "gain", "and", "provides", "a", "real", "unified", "end-to-end", "solution", "for", "the", "whole", "ABSA", "subtasks", ",", "which", "could", "benefit", "multiple", "tasks", "."], "entities": [{"type": "Operation", "start": 100, "end": 104, "text": "pre-training sequence-to-sequence model BART", "sent_idx": 4}, {"type": "Effect", "start": 129, "end": 130, "text": "performance", "sent_idx": 5}], "relations": [{"type": "Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--188"}
{"text": "This paper explores joint syntactic and semantic parsing of Chinese to further improve the performance of both syntactic and semantic parsing, in particular the performance of semantic parsing (in this paper, semantic role labeling). This is done from two levels. Firstly, an integrated parsing approach is proposed to integrate semantic parsing into the syntactic parsing process. Secondly, semantic information generated by semantic parsing is incorporated into the syntactic parsing model to better capture semantic information in syntactic parsing. Evaluation on Chinese TreeBank, Chinese PropBank, and Chinese NomBank shows that our integrated parsing approach outperforms the pipeline parsing approach on n-best parse trees, a natural extension of the widely used pipeline parsing approach on the top-best parse tree. Moreover, it shows that incorporating semantic role-related information into the syntactic parsing model significantly improves the performance of both syntactic parsing and semantic parsing. To our best knowledge, this is the first research on exploring syntactic parsing and semantic role labeling for both verbal and nominal predicates in an integrated way.", "tokens": ["This", "paper", "explores", "joint", "syntactic", "and", "semantic", "parsing", "of", "Chinese", "to", "further", "improve", "the", "performance", "of", "both", "syntactic", "and", "semantic", "parsing", ",", "in", "particular", "the", "performance", "of", "semantic", "parsing", "(", "in", "this", "paper", ",", "semantic", "role", "labeling", ")", ".", "This", "is", "done", "from", "two", "levels", ".", "Firstly", ",", "an", "integrated", "parsing", "approach", "is", "proposed", "to", "integrate", "semantic", "parsing", "into", "the", "syntactic", "parsing", "process", ".", "Secondly", ",", "semantic", "information", "generated", "by", "semantic", "parsing", "is", "incorporated", "into", "the", "syntactic", "parsing", "model", "to", "better", "capture", "semantic", "information", "in", "syntactic", "parsing", ".", "Evaluation", "on", "Chinese", "TreeBank", ",", "Chinese", "PropBank", ",", "and", "Chinese", "NomBank", "shows", "that", "our", "integrated", "parsing", "approach", "outperforms", "the", "pipeline", "parsing", "approach", "on", "n-best", "parse", "trees", ",", "a", "natural", "extension", "of", "the", "widely", "used", "pipeline", "parsing", "approach", "on", "the", "top-best", "parse", "tree", ".", "Moreover", ",", "it", "shows", "that", "incorporating", "semantic", "role-related", "information", "into", "the", "syntactic", "parsing", "model", "significantly", "improves", "the", "performance", "of", "both", "syntactic", "parsing", "and", "semantic", "parsing", ".", "To", "our", "best", "knowledge", ",", "this", "is", "the", "first", "research", "on", "exploring", "syntactic", "parsing", "and", "semantic", "role", "labeling", "for", "both", "verbal", "and", "nominal", "predicates", "in", "an", "integrated", "way", "."], "entities": [{"type": "Operation", "start": 136, "end": 145, "text": "incorporating semantic role-related information into the syntactic parsing model", "sent_idx": 5}, {"type": "Effect", "start": 148, "end": 149, "text": "performance", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "P10-1113"}
{"text": "There is an increasing interest in studying natural language and computer code together, as large corpora of programming texts become readily available on the Internet. For example, StackOverflow currently has over 15 million programming related questions written by 8.5 million users. Meanwhile, there is still a lack of fundamental NLP techniques for identifying code tokens or software-related named entities that appear within natural language sentences. In this paper, we introduce a new named entity recognition (NER) corpus for the computer programming domain, consisting of 15,372 sentences annotated with 20 fine-grained entity types. We trained in-domain BERT representations (BERTOverflow) on 152 million sentences from StackOverflow, which lead to an absolute increase of +10 F1 score over off-the-shelf BERT. We also present the SoftNER model which achieves an overall 79.10 F-1 score for code and named entity recognition on StackOverflow data. Our SoftNER model incorporates a context-independent code token classifier with corpus-level features to improve the BERT-based tagging model. Our code and data are available at: https://github.com/jeniyat/StackOverflowNER/", "tokens": ["There", "is", "an", "increasing", "interest", "in", "studying", "natural", "language", "and", "computer", "code", "together", ",", "as", "large", "corpora", "of", "programming", "texts", "become", "readily", "available", "on", "the", "Internet", ".", "For", "example", ",", "StackOverflow", "currently", "has", "over", "15", "million", "programming", "related", "questions", "written", "by", "8.5", "million", "users", ".", "Meanwhile", ",", "there", "is", "still", "a", "lack", "of", "fundamental", "NLP", "techniques", "for", "identifying", "code", "tokens", "or", "software-related", "named", "entities", "that", "appear", "within", "natural", "language", "sentences", ".", "In", "this", "paper", ",", "we", "introduce", "a", "new", "named", "entity", "recognition", "(", "NER", ")", "corpus", "for", "the", "computer", "programming", "domain", ",", "consisting", "of", "15,372", "sentences", "annotated", "with", "20", "fine-grained", "entity", "types", ".", "We", "trained", "in-domain", "BERT", "representations", "(", "BERTOverflow", ")", "on", "152", "million", "sentences", "from", "StackOverflow", ",", "which", "lead", "to", "an", "absolute", "increase", "of", "+", "10", "F1", "score", "over", "off-the-shelf", "BERT", ".", "We", "also", "present", "the", "SoftNER", "model", "which", "achieves", "an", "overall", "79.10", "F-1", "score", "for", "code", "and", "named", "entity", "recognition", "on", "StackOverflow", "data", ".", "Our", "SoftNER", "model", "incorporates", "a", "context-independent", "code", "token", "classifier", "with", "corpus-level", "features", "to", "improve", "the", "BERT-based", "tagging", "model", ".", "Our", "code", "and", "data", "are", "available", "at", ":", "https://github.com/jeniyat/StackOverflowNER/"], "entities": [{"type": "Operation", "start": 137, "end": 139, "text": "SoftNER model", "sent_idx": 5}, {"type": "Effect", "start": 144, "end": 146, "text": "F-1 score", "sent_idx": 5}, {"type": "Operation", "start": 104, "end": 111, "text": "trained in-domain BERT representations (BERTOverflow)", "sent_idx": 4}, {"type": "Effect", "start": 127, "end": 129, "text": "F1 score", "sent_idx": 4}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 2, "tail": 3}], "id": "abstract-2020--acl-main--443"}
{"text": "Many efforts of research are devoted to semantic role labeling (SRL) which is crucial for natural language understanding. Supervised approaches have achieved impressing performances when large-scale corpora are available for resource-rich languages such as English. While for the low-resource languages with no annotated SRL dataset, it is still challenging to obtain competitive performances. Cross-lingual SRL is one promising way to address the problem, which has achieved great advances with the help of model transferring and annotation projection. In this paper, we propose a novel alternative based on corpus translation, constructing high-quality training datasets for the target languages from the source gold-standard SRL annotations. Experimental results on Universal Proposition Bank show that the translation-based method is highly effective, and the automatic pseudo datasets can improve the target-language SRL performances significantly.", "tokens": ["Many", "efforts", "of", "research", "are", "devoted", "to", "semantic", "role", "labeling", "(", "SRL", ")", "which", "is", "crucial", "for", "natural", "language", "understanding", ".", "Supervised", "approaches", "have", "achieved", "impressing", "performances", "when", "large-scale", "corpora", "are", "available", "for", "resource-rich", "languages", "such", "as", "English", ".", "While", "for", "the", "low-resource", "languages", "with", "no", "annotated", "SRL", "dataset", ",", "it", "is", "still", "challenging", "to", "obtain", "competitive", "performances", ".", "Cross-lingual", "SRL", "is", "one", "promising", "way", "to", "address", "the", "problem", ",", "which", "has", "achieved", "great", "advances", "with", "the", "help", "of", "model", "transferring", "and", "annotation", "projection", ".", "In", "this", "paper", ",", "we", "propose", "a", "novel", "alternative", "based", "on", "corpus", "translation", ",", "constructing", "high-quality", "training", "datasets", "for", "the", "target", "languages", "from", "the", "source", "gold-standard", "SRL", "annotations", ".", "Experimental", "results", "on", "Universal", "Proposition", "Bank", "show", "that", "the", "translation-based", "method", "is", "highly", "effective", ",", "and", "the", "automatic", "pseudo", "datasets", "can", "improve", "the", "target-language", "SRL", "performances", "significantly", "."], "entities": [{"type": "Operation", "start": 131, "end": 134, "text": "automatic pseudo datasets", "sent_idx": 5}, {"type": "Effect", "start": 139, "end": 140, "text": "performances", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--627"}
{"text": "The discovery of supporting evidence for addressing complex mathematical problems is a semantically challenging task, which is still unexplored in the field of natural language processing for mathematical text. The natural language premise selection task consists in using conjectures written in both natural language and mathematical formulae to recommend premises that most likely will be useful to prove a particular statement. We propose an approach to solve this task as a link prediction problem, using Deep Convolutional Graph Neural Networks. This paper also analyses how different baselines perform in this task and shows that a graph structure can provide higher F1-score, especially when considering multi-hop premise selection.", "tokens": ["The", "discovery", "of", "supporting", "evidence", "for", "addressing", "complex", "mathematical", "problems", "is", "a", "semantically", "challenging", "task", ",", "which", "is", "still", "unexplored", "in", "the", "field", "of", "natural", "language", "processing", "for", "mathematical", "text", ".", "The", "natural", "language", "premise", "selection", "task", "consists", "in", "using", "conjectures", "written", "in", "both", "natural", "language", "and", "mathematical", "formulae", "to", "recommend", "premises", "that", "most", "likely", "will", "be", "useful", "to", "prove", "a", "particular", "statement", ".", "We", "propose", "an", "approach", "to", "solve", "this", "task", "as", "a", "link", "prediction", "problem", ",", "using", "Deep", "Convolutional", "Graph", "Neural", "Networks", ".", "This", "paper", "also", "analyses", "how", "different", "baselines", "perform", "in", "this", "task", "and", "shows", "that", "a", "graph", "structure", "can", "provide", "higher", "F1-score", ",", "especially", "when", "considering", "multi-hop", "premise", "selection", "."], "entities": [{"type": "Operation", "start": 100, "end": 102, "text": "graph structure", "sent_idx": 3}, {"type": "Effect", "start": 105, "end": 106, "text": "F1-score", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--657"}
{"text": "We investigate automatic geolocation (i.e. identification of the location, expressed as latitude/longitude coordinates) of documents. Geolocation can be an effective means of summarizing large document collections and it is an important component of geographic information retrieval. We describe several simple supervised methods for document geolocation using only the document's raw text as evidence. All of our methods predict locations in the context of geodesic grids of varying degrees of resolution. We evaluate the methods on geotagged Wikipedia articles and Twitter feeds. For Wikipedia, our best method obtains a median prediction error of just 11.8 kilometers. Twitter geolocation is more challenging: we obtain a median error of 479 km, an improvement on previous results for the dataset.", "tokens": ["We", "investigate", "automatic", "geolocation", "(", "i.e.", "identification", "of", "the", "location", ",", "expressed", "as", "latitude/longitude", "coordinates", ")", "of", "documents", ".", "Geolocation", "can", "be", "an", "effective", "means", "of", "summarizing", "large", "document", "collections", "and", "it", "is", "an", "important", "component", "of", "geographic", "information", "retrieval", ".", "We", "describe", "several", "simple", "supervised", "methods", "for", "document", "geolocation", "using", "only", "the", "document", "'s", "raw", "text", "as", "evidence", ".", "All", "of", "our", "methods", "predict", "locations", "in", "the", "context", "of", "geodesic", "grids", "of", "varying", "degrees", "of", "resolution", ".", "We", "evaluate", "the", "methods", "on", "geotagged", "Wikipedia", "articles", "and", "Twitter", "feeds", ".", "For", "Wikipedia", ",", "our", "best", "method", "obtains", "a", "median", "prediction", "error", "of", "just", "11.8", "kilometers", ".", "Twitter", "geolocation", "is", "more", "challenging", ":", "we", "obtain", "a", "median", "error", "of", "479", "km", ",", "an", "improvement", "on", "previous", "results", "for", "the", "dataset", "."], "entities": [{"type": "Operation", "start": 50, "end": 59, "text": "using only the document's raw text as evidence", "sent_idx": 2}, {"type": "Effect", "start": 98, "end": 101, "text": "median prediction error", "sent_idx": 5}, {"type": "Effect", "start": 115, "end": 117, "text": "median error", "sent_idx": 6}], "relations": [{"type": "Neg_Affect", "head": 0, "tail": 1}, {"type": "Neg_Affect", "head": 0, "tail": 2}], "id": "P11-1096"}
{"text": "Neural networks lack the ability to reason about qualitative physics and so cannot generalize to scenarios and tasks unseen during training. We propose ESPRIT, a framework for commonsense reasoning about qualitative physics in natural language that generates interpretable descriptions of physical events. We use a two-step approach of first identifying the pivotal physical events in an environment and then generating natural language descriptions of those events using a data-to-text approach. Our framework learns to generate explanations of how the physical simulation will causally evolve so that an agent or a human can easily reason about a solution using those interpretable descriptions. Human evaluations indicate that ESPRIT produces crucial fine-grained details and has high coverage of physical concepts compared to even human annotations. Dataset, code and documentation are available at  https://github.com/salesforce/esprit .", "tokens": ["Neural", "networks", "lack", "the", "ability", "to", "reason", "about", "qualitative", "physics", "and", "so", "can", "not", "generalize", "to", "scenarios", "and", "tasks", "unseen", "during", "training", ".", "We", "propose", "ESPRIT", ",", "a", "framework", "for", "commonsense", "reasoning", "about", "qualitative", "physics", "in", "natural", "language", "that", "generates", "interpretable", "descriptions", "of", "physical", "events", ".", "We", "use", "a", "two-step", "approach", "of", "first", "identifying", "the", "pivotal", "physical", "events", "in", "an", "environment", "and", "then", "generating", "natural", "language", "descriptions", "of", "those", "events", "using", "a", "data-to-text", "approach", ".", "Our", "framework", "learns", "to", "generate", "explanations", "of", "how", "the", "physical", "simulation", "will", "causally", "evolve", "so", "that", "an", "agent", "or", "a", "human", "can", "easily", "reason", "about", "a", "solution", "using", "those", "interpretable", "descriptions", ".", "Human", "evaluations", "indicate", "that", "ESPRIT", "produces", "crucial", "fine-grained", "details", "and", "has", "high", "coverage", "of", "physical", "concepts", "compared", "to", "even", "human", "annotations", ".", "Dataset", ",", "code", "and", "documentation", "are", "available", "at", " ", "https://github.com/salesforce/esprit", "."], "entities": [{"type": "Operation", "start": 111, "end": 112, "text": "ESPRIT", "sent_idx": 4}, {"type": "Effect", "start": 119, "end": 123, "text": "coverage of physical concepts", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--706"}
{"text": "We present an ILP-based model of zero anaphora detection and resolution that builds on the joint determination of anaphoricity and coreference model proposed by Denis and Baldridge (2007), but revises it and extends it into a three-way ILP problem also incorporating subject detection. We show that this new model outperforms several baselines and competing models, as well as a direct translation of the Denis/Baldridge model, for both Italian and Japanese zero anaphora. We incorporate our model in complete anaphoric resolvers for both Italian and Japanese, showing that our approach leads to improved performance also when not used in isolation, provided that separate classifiers are used for zeros and for explicitly realized anaphors.", "tokens": ["We", "present", "an", "ILP-based", "model", "of", "zero", "anaphora", "detection", "and", "resolution", "that", "builds", "on", "the", "joint", "determination", "of", "anaphoricity", "and", "coreference", "model", "proposed", "by", "Denis", "and", "Baldridge", "(", "2007", ")", ",", "but", "revises", "it", "and", "extends", "it", "into", "a", "three-way", "ILP", "problem", "also", "incorporating", "subject", "detection", ".", "We", "show", "that", "this", "new", "model", "outperforms", "several", "baselines", "and", "competing", "models", ",", "as", "well", "as", "a", "direct", "translation", "of", "the", "Denis/Baldridge", "model", ",", "for", "both", "Italian", "and", "Japanese", "zero", "anaphora", ".", "We", "incorporate", "our", "model", "in", "complete", "anaphoric", "resolvers", "for", "both", "Italian", "and", "Japanese", ",", "showing", "that", "our", "approach", "leads", "to", "improved", "performance", "also", "when", "not", "used", "in", "isolation", ",", "provided", "that", "separate", "classifiers", "are", "used", "for", "zeros", "and", "for", "explicitly", "realized", "anaphors", "."], "entities": [{"type": "Operation", "start": 3, "end": 5, "text": "ILP-based model", "sent_idx": 0}, {"type": "Effect", "start": 100, "end": 101, "text": "performance", "sent_idx": 2}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "P11-1081"}
{"text": "Part-of-Speech (POS) tags are routinely included as features in many NLP tasks. However, the importance and usefulness of POS tags needs to be examined as NLP expands to low-resource languages because linguists who provide many annotated resources do not place priority on early identification and tagging of POS. This paper describes an empirical study about the effect that POS tags have on two computational morphological tasks with the Transformer architecture. Each task is tested twice on identical data except for the presence/absence of POS tags, using published data in ten high- to low-resource languages or unpublished linguistic field data in five low-resource languages. We find that the presence or absence of POS tags does not have a significant bearing on performance. In joint segmentation and glossing, the largest average difference is an .09 improvement in F1-scores by removing POS tags. In reinflection, the greatest average difference is 1.2% in accuracy for published data and 5% for unpublished and noisy field data.", "tokens": ["Part-of-Speech", "(", "POS", ")", "tags", "are", "routinely", "included", "as", "features", "in", "many", "NLP", "tasks", ".", "However", ",", "the", "importance", "and", "usefulness", "of", "POS", "tags", "needs", "to", "be", "examined", "as", "NLP", "expands", "to", "low-resource", "languages", "because", "linguists", "who", "provide", "many", "annotated", "resources", "do", "not", "place", "priority", "on", "early", "identification", "and", "tagging", "of", "POS", ".", "This", "paper", "describes", "an", "empirical", "study", "about", "the", "effect", "that", "POS", "tags", "have", "on", "two", "computational", "morphological", "tasks", "with", "the", "Transformer", "architecture", ".", "Each", "task", "is", "tested", "twice", "on", "identical", "data", "except", "for", "the", "presence/absence", "of", "POS", "tags", ",", "using", "published", "data", "in", "ten", "high-", "to", "low-resource", "languages", "or", "unpublished", "linguistic", "field", "data", "in", "five", "low-resource", "languages", ".", "We", "find", "that", "the", "presence", "or", "absence", "of", "POS", "tags", "does", "not", "have", "a", "significant", "bearing", "on", "performance", ".", "In", "joint", "segmentation", "and", "glossing", ",", "the", "largest", "average", "difference", "is", "an", ".09", "improvement", "in", "F1-scores", "by", "removing", "POS", "tags", ".", "In", "reinflection", ",", "the", "greatest", "average", "difference", "is", "1.2", "%", "in", "accuracy", "for", "published", "data", "and", "5", "%", "for", "unpublished", "and", "noisy", "field", "data", "."], "entities": [{"type": "Operation", "start": 147, "end": 150, "text": "removing POS tags", "sent_idx": 5}, {"type": "Effect", "start": 145, "end": 146, "text": "F1-scores", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--78"}
{"text": "We present a thorough comparison of two principal approaches to Cross-Lingual Information Retrieval: document translation (DT) and query translation (QT). Our experiments are conducted using the cross-lingual test collection produced within the CLEF eHealth information retrieval tasks in 2013\u20132015 containing English documents and queries in several European languages. We exploit the Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) paradigms and train several domain-specific and task-specific machine translation systems to translate the non-English queries into English (for the QT approach) and the English documents to all the query languages (for the DT approach). The results show that the quality of QT by SMT is sufficient enough to outperform the retrieval results of the DT approach for all the languages. NMT then further boosts translation quality and retrieval quality for both QT and DT for most languages, but still, QT provides generally better retrieval results than DT.", "tokens": ["We", "present", "a", "thorough", "comparison", "of", "two", "principal", "approaches", "to", "Cross-Lingual", "Information", "Retrieval", ":", "document", "translation", "(", "DT", ")", "and", "query", "translation", "(", "QT", ")", ".", "Our", "experiments", "are", "conducted", "using", "the", "cross-lingual", "test", "collection", "produced", "within", "the", "CLEF", "eHealth", "information", "retrieval", "tasks", "in", "2013\u20132015", "containing", "English", "documents", "and", "queries", "in", "several", "European", "languages", ".", "We", "exploit", "the", "Statistical", "Machine", "Translation", "(", "SMT", ")", "and", "Neural", "Machine", "Translation", "(", "NMT", ")", "paradigms", "and", "train", "several", "domain-specific", "and", "task-specific", "machine", "translation", "systems", "to", "translate", "the", "non-English", "queries", "into", "English", "(", "for", "the", "QT", "approach", ")", "and", "the", "English", "documents", "to", "all", "the", "query", "languages", "(", "for", "the", "DT", "approach", ")", ".", "The", "results", "show", "that", "the", "quality", "of", "QT", "by", "SMT", "is", "sufficient", "enough", "to", "outperform", "the", "retrieval", "results", "of", "the", "DT", "approach", "for", "all", "the", "languages", ".", "NMT", "then", "further", "boosts", "translation", "quality", "and", "retrieval", "quality", "for", "both", "QT", "and", "DT", "for", "most", "languages", ",", "but", "still", ",", "QT", "provides", "generally", "better", "retrieval", "results", "than", "DT", "."], "entities": [{"type": "Operation", "start": 137, "end": 138, "text": "NMT", "sent_idx": 4}, {"type": "Effect", "start": 141, "end": 143, "text": "translation quality", "sent_idx": 4}, {"type": "Effect", "start": 144, "end": 146, "text": "retrieval quality", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 0, "tail": 2}], "id": "abstract-2020--acl-main--613"}
{"text": "The automatic text-based diagnosis remains a challenging task for clinical use because it requires appropriate balance between accuracy and interpretability. In this paper, we attempt to propose a solution by introducing a novel framework that stacks Bayesian Network Ensembles on top of Entity-Aware Convolutional Neural Networks (CNN) towards building an accurate yet interpretable diagnosis system. The proposed framework takes advantage of the high accuracy and generality of deep neural networks as well as the interpretability of Bayesian Networks, which is critical for AI-empowered healthcare. The evaluation conducted on the real Electronic Medical Record (EMR) documents from hospitals and annotated by professional doctors proves that, the proposed framework outperforms the previous automatic diagnosis methods in accuracy performance and the diagnosis explanation of the framework is reasonable.", "tokens": ["The", "automatic", "text-based", "diagnosis", "remains", "a", "challenging", "task", "for", "clinical", "use", "because", "it", "requires", "appropriate", "balance", "between", "accuracy", "and", "interpretability", ".", "In", "this", "paper", ",", "we", "attempt", "to", "propose", "a", "solution", "by", "introducing", "a", "novel", "framework", "that", "stacks", "Bayesian", "Network", "Ensembles", "on", "top", "of", "Entity-Aware", "Convolutional", "Neural", "Networks", "(", "CNN", ")", "towards", "building", "an", "accurate", "yet", "interpretable", "diagnosis", "system", ".", "The", "proposed", "framework", "takes", "advantage", "of", "the", "high", "accuracy", "and", "generality", "of", "deep", "neural", "networks", "as", "well", "as", "the", "interpretability", "of", "Bayesian", "Networks", ",", "which", "is", "critical", "for", "AI-empowered", "healthcare", ".", "The", "evaluation", "conducted", "on", "the", "real", "Electronic", "Medical", "Record", "(", "EMR", ")", "documents", "from", "hospitals", "and", "annotated", "by", "professional", "doctors", "proves", "that", ",", "the", "proposed", "framework", "outperforms", "the", "previous", "automatic", "diagnosis", "methods", "in", "accuracy", "performance", "and", "the", "diagnosis", "explanation", "of", "the", "framework", "is", "reasonable", "."], "entities": [{"type": "Operation", "start": 37, "end": 51, "text": "stacks Bayesian Network Ensembles on top of Entity-Aware Convolutional Neural Networks (CNN)", "sent_idx": 1}, {"type": "Effect", "start": 124, "end": 126, "text": "accuracy performance", "sent_idx": 3}], "relations": [{"type": "Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--286"}
{"text": "While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.", "tokens": ["While", "state-of-the-art", "neural", "network", "models", "continue", "to", "achieve", "lower", "perplexity", "scores", "on", "language", "modeling", "benchmarks", ",", "it", "remains", "unknown", "whether", "optimizing", "for", "broad-coverage", "predictive", "performance", "leads", "to", "human-like", "syntactic", "knowledge", ".", "Furthermore", ",", "existing", "work", "has", "not", "provided", "a", "clear", "picture", "about", "the", "model", "properties", "required", "to", "produce", "proper", "syntactic", "generalizations", ".", "We", "present", "a", "systematic", "evaluation", "of", "the", "syntactic", "knowledge", "of", "neural", "language", "models", ",", "testing", "20", "combinations", "of", "model", "types", "and", "data", "sizes", "on", "a", "set", "of", "34", "English-language", "syntactic", "test", "suites", ".", "We", "find", "substantial", "differences", "in", "syntactic", "generalization", "performance", "by", "model", "architecture", ",", "with", "sequential", "models", "underperforming", "other", "architectures", ".", "Factorially", "manipulating", "model", "architecture", "and", "training", "dataset", "size", "(", "1M-40", "M", "words", ")", ",", "we", "find", "that", "variability", "in", "syntactic", "generalization", "performance", "is", "substantially", "greater", "by", "architecture", "than", "by", "dataset", "size", "for", "the", "corpora", "tested", "in", "our", "experiments", ".", "Our", "results", "also", "reveal", "a", "dissociation", "between", "perplexity", "and", "syntactic", "generalization", "performance", "."], "entities": [{"type": "Operation", "start": 130, "end": 131, "text": "architecture", "sent_idx": 4}, {"type": "Effect", "start": 125, "end": 126, "text": "performance", "sent_idx": 4}, {"type": "Operation", "start": 133, "end": 135, "text": "dataset size", "sent_idx": 4}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 2, "tail": 1}], "id": "abstract-2020--acl-main--158"}
{"text": "Structured information is an important knowledge source for automatic verification of factual claims. Nevertheless, the majority of existing research into this task has focused on textual data, and the few recent inquiries into structured data have been for the closed-domain setting where appropriate evidence for each claim is assumed to have already been retrieved. In this paper, we investigate verification over structured data in the open-domain setting, introducing a joint reranking-and-verification model which fuses evidence documents in the verification component. Our open-domain model achieves performance comparable to the closed-domain state-of-the-art on the TabFact dataset, and demonstrates performance gains from the inclusion of multiple tables as well as a significant improvement over a heuristic retrieval baseline.", "tokens": ["Structured", "information", "is", "an", "important", "knowledge", "source", "for", "automatic", "verification", "of", "factual", "claims", ".", "Nevertheless", ",", "the", "majority", "of", "existing", "research", "into", "this", "task", "has", "focused", "on", "textual", "data", ",", "and", "the", "few", "recent", "inquiries", "into", "structured", "data", "have", "been", "for", "the", "closed-domain", "setting", "where", "appropriate", "evidence", "for", "each", "claim", "is", "assumed", "to", "have", "already", "been", "retrieved", ".", "In", "this", "paper", ",", "we", "investigate", "verification", "over", "structured", "data", "in", "the", "open-domain", "setting", ",", "introducing", "a", "joint", "reranking-and-verification", "model", "which", "fuses", "evidence", "documents", "in", "the", "verification", "component", ".", "Our", "open-domain", "model", "achieves", "performance", "comparable", "to", "the", "closed-domain", "state-of-the-art", "on", "the", "TabFact", "dataset", ",", "and", "demonstrates", "performance", "gains", "from", "the", "inclusion", "of", "multiple", "tables", "as", "well", "as", "a", "significant", "improvement", "over", "a", "heuristic", "retrieval", "baseline", "."], "entities": [{"type": "Operation", "start": 88, "end": 90, "text": "open-domain model", "sent_idx": 3}, {"type": "Effect", "start": 104, "end": 105, "text": "performance", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--529"}
{"text": "Exploiting natural language processing in the clinical domain requires de-identification, i.e., anonymization of personal information in texts. However, current research considers de-identification and downstream tasks, such as concept extraction, only in isolation and does not study the effects of de-identification on other tasks. In this paper, we close this gap by reporting concept extraction performance on automatically anonymized data and investigating joint models for de-identification and concept extraction. In particular, we propose a stacked model with restricted access to privacy sensitive information and a multitask model. We set the new state of the art on benchmark datasets in English (96.1% F1 for de-identification and 88.9% F1 for concept extraction) and Spanish (91.4% F1 for concept extraction).", "tokens": ["Exploiting", "natural", "language", "processing", "in", "the", "clinical", "domain", "requires", "de-identification", ",", "i.e.", ",", "anonymization", "of", "personal", "information", "in", "texts", ".", "However", ",", "current", "research", "considers", "de-identification", "and", "downstream", "tasks", ",", "such", "as", "concept", "extraction", ",", "only", "in", "isolation", "and", "does", "not", "study", "the", "effects", "of", "de-identification", "on", "other", "tasks", ".", "In", "this", "paper", ",", "we", "close", "this", "gap", "by", "reporting", "concept", "extraction", "performance", "on", "automatically", "anonymized", "data", "and", "investigating", "joint", "models", "for", "de-identification", "and", "concept", "extraction", ".", "In", "particular", ",", "we", "propose", "a", "stacked", "model", "with", "restricted", "access", "to", "privacy", "sensitive", "information", "and", "a", "multitask", "model", ".", "We", "set", "the", "new", "state", "of", "the", "art", "on", "benchmark", "datasets", "in", "English", "(", "96.1", "%", "F1", "for", "de-identification", "and", "88.9", "%", "F1", "for", "concept", "extraction", ")", "and", "Spanish", "(", "91.4", "%", "F1", "for", "concept", "extraction", ")", "."], "entities": [{"type": "Operation", "start": 82, "end": 88, "text": "a stacked model with restricted access", "sent_idx": 3}, {"type": "Effect", "start": 113, "end": 114, "text": "F1", "sent_idx": 4}, {"type": "Operation", "start": 93, "end": 96, "text": "a multitask model", "sent_idx": 3}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 2, "tail": 1}], "id": "abstract-2020--acl-main--621"}
{"text": "Learning contextual text embeddings that represent causal graphs has been useful in improving the performance of downstream tasks like causal treatment effect estimation. However, existing causal embeddings which are trained to predict direct causal links, fail to capture other indirect causal links of the graph, thus leading to spurious correlations in downstream tasks. In this paper, we define the faithfulness property of contextual embeddings to capture geometric distance-based properties of directed acyclic causal graphs. By incorporating these faithfulness properties, we learn text embeddings that are 31.3% more faithful to human validated causal graphs with about 800K and 200K causal links and achieve 21.1% better Precision-Recall AUC in a link prediction fine-tuning task. Further, in a crowdsourced causal question-answering task on Yahoo! Answers with questions of the form \u201cWhat causes X?\u201d, our faithful embeddings achieved a precision of the first ranked answer (P@1) of 41.07%, outperforming the existing baseline by 10.2%.", "tokens": ["Learning", "contextual", "text", "embeddings", "that", "represent", "causal", "graphs", "has", "been", "useful", "in", "improving", "the", "performance", "of", "downstream", "tasks", "like", "causal", "treatment", "effect", "estimation", ".", "However", ",", "existing", "causal", "embeddings", "which", "are", "trained", "to", "predict", "direct", "causal", "links", ",", "fail", "to", "capture", "other", "indirect", "causal", "links", "of", "the", "graph", ",", "thus", "leading", "to", "spurious", "correlations", "in", "downstream", "tasks", ".", "In", "this", "paper", ",", "we", "define", "the", "faithfulness", "property", "of", "contextual", "embeddings", "to", "capture", "geometric", "distance-based", "properties", "of", "directed", "acyclic", "causal", "graphs", ".", "By", "incorporating", "these", "faithfulness", "properties", ",", "we", "learn", "text", "embeddings", "that", "are", "31.3", "%", "more", "faithful", "to", "human", "validated", "causal", "graphs", "with", "about", "800", "K", "and", "200", "K", "causal", "links", "and", "achieve", "21.1", "%", "better", "Precision-Recall", "AUC", "in", "a", "link", "prediction", "fine-tuning", "task", ".", "Further", ",", "in", "a", "crowdsourced", "causal", "question-answering", "task", "on", "Yahoo", "!", "Answers", "with", "questions", "of", "the", "form", "\u201c", "What", "causes", "X", "?", "\u201d", ",", "our", "faithful", "embeddings", "achieved", "a", "precision", "of", "the", "first", "ranked", "answer", "(", "P@1", ")", "of", "41.07", "%", ",", "outperforming", "the", "existing", "baseline", "by", "10.2", "%", "."], "entities": [{"type": "Operation", "start": 150, "end": 152, "text": "faithful embeddings", "sent_idx": 4}, {"type": "Effect", "start": 161, "end": 162, "text": "P@1", "sent_idx": 4}], "relations": [{"type": "Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--69"}
{"text": "This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https://github.com/tag-and-generate.", "tokens": ["This", "paper", "introduces", "a", "new", "task", "of", "politeness", "transfer", "which", "involves", "converting", "non-polite", "sentences", "to", "polite", "sentences", "while", "preserving", "the", "meaning", ".", "We", "also", "provide", "a", "dataset", "of", "more", "than", "1.39", "instances", "automatically", "labeled", "for", "politeness", "to", "encourage", "benchmark", "evaluations", "on", "this", "new", "task", ".", "We", "design", "a", "tag", "and", "generate", "pipeline", "that", "identifies", "stylistic", "attributes", "and", "subsequently", "generates", "a", "sentence", "in", "the", "target", "style", "while", "preserving", "most", "of", "the", "source", "content", ".", "For", "politeness", "as", "well", "as", "five", "other", "transfer", "tasks", ",", "our", "model", "outperforms", "the", "state-of-the-art", "methods", "on", "automatic", "metrics", "for", "content", "preservation", ",", "with", "a", "comparable", "or", "better", "performance", "on", "style", "transfer", "accuracy", ".", "Additionally", ",", "our", "model", "surpasses", "existing", "methods", "on", "human", "evaluations", "for", "grammaticality", ",", "meaning", "preservation", "and", "transfer", "accuracy", "across", "all", "the", "six", "style", "transfer", "tasks", ".", "The", "data", "and", "code", "is", "located", "at", "https://github.com/tag-and-generate", "."], "entities": [{"type": "Operation", "start": 47, "end": 52, "text": "a tag and generate pipeline", "sent_idx": 2}, {"type": "Effect", "start": 101, "end": 102, "text": "performance", "sent_idx": 3}, {"type": "Effect", "start": 103, "end": 106, "text": "style transfer accuracy", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 0, "tail": 2}], "id": "abstract-2020--acl-main--169"}
{"text": "As described in this paper, we propose a new automatic evaluation method for machine translation using noun-phrase chunking. Our method correctly determines the matching words between two sentences using corresponding noun phrases. Moreover, our method determines the similarity between two sentences in terms of the noun-phrase order of appearance. Evaluation experiments were conducted to calculate the correlation among human judgments, along with the scores produced using automatic evaluation methods for MT outputs obtained from the 12 machine translation systems in NTCIR-7. Experimental results show that our method obtained the highest correlations among the methods in both sentence-level adequacy and fluency.", "tokens": ["As", "described", "in", "this", "paper", ",", "we", "propose", "a", "new", "automatic", "evaluation", "method", "for", "machine", "translation", "using", "noun-phrase", "chunking", ".", "Our", "method", "correctly", "determines", "the", "matching", "words", "between", "two", "sentences", "using", "corresponding", "noun", "phrases", ".", "Moreover", ",", "our", "method", "determines", "the", "similarity", "between", "two", "sentences", "in", "terms", "of", "the", "noun-phrase", "order", "of", "appearance", ".", "Evaluation", "experiments", "were", "conducted", "to", "calculate", "the", "correlation", "among", "human", "judgments", ",", "along", "with", "the", "scores", "produced", "using", "automatic", "evaluation", "methods", "for", "MT", "outputs", "obtained", "from", "the", "12", "machine", "translation", "systems", "in", "NTCIR-7", ".", "Experimental", "results", "show", "that", "our", "method", "obtained", "the", "highest", "correlations", "among", "the", "methods", "in", "both", "sentence-level", "adequacy", "and", "fluency", "."], "entities": [{"type": "Operation", "start": 17, "end": 19, "text": "noun-phrase chunking", "sent_idx": 0}, {"type": "Effect", "start": 104, "end": 105, "text": "adequacy", "sent_idx": 4}, {"type": "Effect", "start": 106, "end": 107, "text": "fluency", "sent_idx": 4}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}], "id": "P10-1012"}
{"text": "Complex compositional reading comprehension datasets require performing latent sequential decisions that are learned via supervision from the final answer. A large combinatorial space of possible decision paths that result in the same answer, compounded by the lack of intermediate supervision to help choose the right path, makes the learning particularly hard for this task. In this work, we study the benefits of collecting intermediate reasoning supervision along with the answer during data collection. We find that these intermediate annotations can provide two-fold benefits. First, we observe that for any collection budget, spending a fraction of it on intermediate annotations results in improved model performance, for two complex compositional datasets: DROP and Quoref. Second, these annotations encourage the model to learn the correct latent reasoning steps, helping combat some of the biases introduced during the data collection process.", "tokens": ["Complex", "compositional", "reading", "comprehension", "datasets", "require", "performing", "latent", "sequential", "decisions", "that", "are", "learned", "via", "supervision", "from", "the", "final", "answer", ".", "A", "large", "combinatorial", "space", "of", "possible", "decision", "paths", "that", "result", "in", "the", "same", "answer", ",", "compounded", "by", "the", "lack", "of", "intermediate", "supervision", "to", "help", "choose", "the", "right", "path", ",", "makes", "the", "learning", "particularly", "hard", "for", "this", "task", ".", "In", "this", "work", ",", "we", "study", "the", "benefits", "of", "collecting", "intermediate", "reasoning", "supervision", "along", "with", "the", "answer", "during", "data", "collection", ".", "We", "find", "that", "these", "intermediate", "annotations", "can", "provide", "two-fold", "benefits", ".", "First", ",", "we", "observe", "that", "for", "any", "collection", "budget", ",", "spending", "a", "fraction", "of", "it", "on", "intermediate", "annotations", "results", "in", "improved", "model", "performance", ",", "for", "two", "complex", "compositional", "datasets", ":", "DROP", "and", "Quoref", ".", "Second", ",", "these", "annotations", "encourage", "the", "model", "to", "learn", "the", "correct", "latent", "reasoning", "steps", ",", "helping", "combat", "some", "of", "the", "biases", "introduced", "during", "the", "data", "collection", "process", "."], "entities": [{"type": "Operation", "start": 106, "end": 108, "text": "intermediate annotations", "sent_idx": 4}, {"type": "Effect", "start": 112, "end": 113, "text": "performance", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--497"}
{"text": "In recent years, math word problem solving has received considerable attention and achieved promising results, but previous methods rarely take numerical values into consideration. Most methods treat the numerical values in the problems as number symbols, and ignore the prominent role of the numerical values in solving the problem. In this paper, we propose a novel approach called NumS2T, which enhances math word problem solving performance by explicitly incorporating numerical values into a sequence-to-tree network. In addition, a numerical properties prediction mechanism is used to capture the category and comparison information of numerals and measure their importance in global expressions. Experimental results on the Math23K and APE datasets demonstrate that our model achieves better performance than existing state-of-the-art models.", "tokens": ["In", "recent", "years", ",", "math", "word", "problem", "solving", "has", "received", "considerable", "attention", "and", "achieved", "promising", "results", ",", "but", "previous", "methods", "rarely", "take", "numerical", "values", "into", "consideration", ".", "Most", "methods", "treat", "the", "numerical", "values", "in", "the", "problems", "as", "number", "symbols", ",", "and", "ignore", "the", "prominent", "role", "of", "the", "numerical", "values", "in", "solving", "the", "problem", ".", "In", "this", "paper", ",", "we", "propose", "a", "novel", "approach", "called", "NumS2", "T", ",", "which", "enhances", "math", "word", "problem", "solving", "performance", "by", "explicitly", "incorporating", "numerical", "values", "into", "a", "sequence-to-tree", "network", ".", "In", "addition", ",", "a", "numerical", "properties", "prediction", "mechanism", "is", "used", "to", "capture", "the", "category", "and", "comparison", "information", "of", "numerals", "and", "measure", "their", "importance", "in", "global", "expressions", ".", "Experimental", "results", "on", "the", "Math23", "K", "and", "APE", "datasets", "demonstrate", "that", "our", "model", "achieves", "better", "performance", "than", "existing", "state-of-the-art", "models", "."], "entities": [{"type": "Operation", "start": 64, "end": 66, "text": "NumS2T", "sent_idx": 2}, {"type": "Effect", "start": 126, "end": 127, "text": "performance", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--455"}
{"text": "Knowledge distillation has been proven to be effective in model acceleration and compression. It transfers knowledge from a large neural network to a small one by using the large neural network predictions as targets of the small neural network. But this way ignores the knowledge inside the large neural networks, e.g., parameters. Our preliminary study as well as the recent success in pre-training suggests that transferring parameters are more effective in distilling knowledge. In this paper, we propose Weight Distillation to transfer the knowledge in parameters of a large neural network to a small neural network through a parameter generator. On the WMT16 En-Ro, NIST12 Zh-En, and WMT14 En-De machine translation tasks, our experiments show that weight distillation learns a small network that is 1.88 2.94x faster than the large network but with competitive BLEU performance. When fixing the size of small networks, weight distillation outperforms knowledge distillation by 0.51 1.82 BLEU points.", "tokens": ["Knowledge", "distillation", "has", "been", "proven", "to", "be", "effective", "in", "model", "acceleration", "and", "compression", ".", "It", "transfers", "knowledge", "from", "a", "large", "neural", "network", "to", "a", "small", "one", "by", "using", "the", "large", "neural", "network", "predictions", "as", "targets", "of", "the", "small", "neural", "network", ".", "But", "this", "way", "ignores", "the", "knowledge", "inside", "the", "large", "neural", "networks", ",", "e.g.", ",", "parameters", ".", "Our", "preliminary", "study", "as", "well", "as", "the", "recent", "success", "in", "pre-training", "suggests", "that", "transferring", "parameters", "are", "more", "effective", "in", "distilling", "knowledge", ".", "In", "this", "paper", ",", "we", "propose", "Weight", "Distillation", "to", "transfer", "the", "knowledge", "in", "parameters", "of", "a", "large", "neural", "network", "to", "a", "small", "neural", "network", "through", "a", "parameter", "generator", ".", "On", "the", "WMT16", "En-Ro", ",", "NIST12", "Zh-En", ",", "and", "WMT14", "En-De", "machine", "translation", "tasks", ",", "our", "experiments", "show", "that", "weight", "distillation", "learns", "a", "small", "network", "that", "is", "1.88", "2.94x", "faster", "than", "the", "large", "network", "but", "with", "competitive", "BLEU", "performance", ".", "When", "fixing", "the", "size", "of", "small", "networks", ",", "weight", "distillation", "outperforms", "knowledge", "distillation", "by", "0.51", "1.82", "BLEU", "points", "."], "entities": [{"type": "Operation", "start": 127, "end": 129, "text": "weight distillation", "sent_idx": 4}, {"type": "Effect", "start": 145, "end": 146, "text": "BLEU", "sent_idx": 4}], "relations": [{"type": "Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--162"}
{"text": "The aspect-based sentiment analysis (ABSA) consists of two conceptual tasks, namely an aspect extraction and an aspect sentiment classification. Rather than considering the tasks separately, we build an end-to-end ABSA solution. Previous works in ABSA tasks did not fully leverage the importance of syntactical information. Hence, the aspect extraction model often failed to detect the boundaries of multi-word aspect terms. On the other hand, the aspect sentiment classifier was unable to account for the syntactical correlation between aspect terms and the context words. This paper explores the grammatical aspect of the sentence and employs the self-attention mechanism for syntactical learning. We combine part-of-speech embeddings, dependency-based embeddings and contextualized embeddings (e.g. BERT, RoBERTa) to enhance the performance of the aspect extractor. We also propose the syntactic relative distance to de-emphasize the adverse effects of unrelated words, having weak syntactic connection with the aspect terms. This increases the accuracy of the aspect sentiment classifier. Our solutions outperform the state-of-the-art models on SemEval-2014 dataset in both two subtasks.", "tokens": ["The", "aspect-based", "sentiment", "analysis", "(", "ABSA", ")", "consists", "of", "two", "conceptual", "tasks", ",", "namely", "an", "aspect", "extraction", "and", "an", "aspect", "sentiment", "classification", ".", "Rather", "than", "considering", "the", "tasks", "separately", ",", "we", "build", "an", "end-to-end", "ABSA", "solution", ".", "Previous", "works", "in", "ABSA", "tasks", "did", "not", "fully", "leverage", "the", "importance", "of", "syntactical", "information", ".", "Hence", ",", "the", "aspect", "extraction", "model", "often", "failed", "to", "detect", "the", "boundaries", "of", "multi-word", "aspect", "terms", ".", "On", "the", "other", "hand", ",", "the", "aspect", "sentiment", "classifier", "was", "unable", "to", "account", "for", "the", "syntactical", "correlation", "between", "aspect", "terms", "and", "the", "context", "words", ".", "This", "paper", "explores", "the", "grammatical", "aspect", "of", "the", "sentence", "and", "employs", "the", "self-attention", "mechanism", "for", "syntactical", "learning", ".", "We", "combine", "part-of-speech", "embeddings", ",", "dependency-based", "embeddings", "and", "contextualized", "embeddings", "(", "e.g.", "BERT", ",", "RoBERTa", ")", "to", "enhance", "the", "performance", "of", "the", "aspect", "extractor", ".", "We", "also", "propose", "the", "syntactic", "relative", "distance", "to", "de-emphasize", "the", "adverse", "effects", "of", "unrelated", "words", ",", "having", "weak", "syntactic", "connection", "with", "the", "aspect", "terms", ".", "This", "increases", "the", "accuracy", "of", "the", "aspect", "sentiment", "classifier", ".", "Our", "solutions", "outperform", "the", "state-of-the-art", "models", "on", "SemEval-2014", "dataset", "in", "both", "two", "subtasks", "."], "entities": [{"type": "Operation", "start": 141, "end": 144, "text": "syntactic relative distance", "sent_idx": 7}, {"type": "Effect", "start": 165, "end": 166, "text": "accuracy", "sent_idx": 8}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--293"}
{"text": "The goal of conversational machine reading is to answer user questions given a knowledge base text which may require asking clarification questions. Existing approaches are limited in their decision making due to struggles in extracting question-related rules and reasoning about them. In this paper, we present a new framework of conversational machine reading that comprises a novel Explicit Memory Tracker (EMT) to track whether conditions listed in the rule text have already been satisfied to make a decision. Moreover, our framework generates clarification questions by adopting a coarse-to-fine reasoning strategy, utilizing sentence-level entailment scores to weight token-level distributions. On the ShARC benchmark (blind, held-out) testset, EMT achieves new state-of-the-art results of 74.6% micro-averaged decision accuracy and 49.5 BLEU4. We also show that EMT is more interpretable by visualizing the entailment-oriented reasoning process as the conversation flows. Code and models are released at https://github.com/Yifan-Gao/explicit_memory_tracker.", "tokens": ["The", "goal", "of", "conversational", "machine", "reading", "is", "to", "answer", "user", "questions", "given", "a", "knowledge", "base", "text", "which", "may", "require", "asking", "clarification", "questions", ".", "Existing", "approaches", "are", "limited", "in", "their", "decision", "making", "due", "to", "struggles", "in", "extracting", "question-related", "rules", "and", "reasoning", "about", "them", ".", "In", "this", "paper", ",", "we", "present", "a", "new", "framework", "of", "conversational", "machine", "reading", "that", "comprises", "a", "novel", "Explicit", "Memory", "Tracker", "(", "EMT", ")", "to", "track", "whether", "conditions", "listed", "in", "the", "rule", "text", "have", "already", "been", "satisfied", "to", "make", "a", "decision", ".", "Moreover", ",", "our", "framework", "generates", "clarification", "questions", "by", "adopting", "a", "coarse-to-fine", "reasoning", "strategy", ",", "utilizing", "sentence-level", "entailment", "scores", "to", "weight", "token-level", "distributions", ".", "On", "the", "ShARC", "benchmark", "(", "blind", ",", "held-out", ")", "testset", ",", "EMT", "achieves", "new", "state-of-the-art", "results", "of", "74.6", "%", "micro-averaged", "decision", "accuracy", "and", "49.5", "BLEU4", ".", "We", "also", "show", "that", "EMT", "is", "more", "interpretable", "by", "visualizing", "the", "entailment-oriented", "reasoning", "process", "as", "the", "conversation", "flows", ".", "Code", "and", "models", "are", "released", "at", "https://github.com/Yifan-Gao/explicit_memory_tracker", "."], "entities": [{"type": "Operation", "start": 118, "end": 119, "text": "EMT", "sent_idx": 4}, {"type": "Effect", "start": 126, "end": 129, "text": "micro-averaged decision accuracy", "sent_idx": 4}, {"type": "Effect", "start": 131, "end": 132, "text": "BLEU4", "sent_idx": 4}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}], "id": "abstract-2020--acl-main--88"}
{"text": "Despite the success of sequence-to-sequence (seq2seq) models in semantic parsing, recent work has shown that they fail in compositional generalization, i.e., the ability to generalize to new structures built of components observed during training. In this work, we posit that a span-based parser should lead to better compositional generalization. we propose SpanBasedSP, a parser that predicts a span tree over an input utterance, explicitly encoding how partial programs compose over spans in the input. SpanBasedSP extends Pasupat et al. (2019) to be comparable to seq2seq models by (i) training from programs, without access to gold trees, treating trees as latent variables, (ii) parsing a class of non-projective trees through an extension to standard CKY. On GeoQuery, SCAN and CLOSURE datasets, SpanBasedSP performs similarly to strong seq2seq baselines on random splits, but dramatically improves performance compared to baselines on splits that require compositional generalization: from 61.0 \u2192 88.9 average accuracy.", "tokens": ["Despite", "the", "success", "of", "sequence-to-sequence", "(", "seq2seq", ")", "models", "in", "semantic", "parsing", ",", "recent", "work", "has", "shown", "that", "they", "fail", "in", "compositional", "generalization", ",", "i.e.", ",", "the", "ability", "to", "generalize", "to", "new", "structures", "built", "of", "components", "observed", "during", "training", ".", "In", "this", "work", ",", "we", "posit", "that", "a", "span-based", "parser", "should", "lead", "to", "better", "compositional", "generalization", ".", "we", "propose", "SpanBasedSP", ",", "a", "parser", "that", "predicts", "a", "span", "tree", "over", "an", "input", "utterance", ",", "explicitly", "encoding", "how", "partial", "programs", "compose", "over", "spans", "in", "the", "input", ".", "SpanBasedSP", "extends", "Pasupat", "et", "al.", "(", "2019", ")", "to", "be", "comparable", "to", "seq2seq", "models", "by", "(", "i", ")", "training", "from", "programs", ",", "without", "access", "to", "gold", "trees", ",", "treating", "trees", "as", "latent", "variables", ",", "(", "ii", ")", "parsing", "a", "class", "of", "non-projective", "trees", "through", "an", "extension", "to", "standard", "CKY", ".", "On", "GeoQuery", ",", "SCAN", "and", "CLOSURE", "datasets", ",", "SpanBasedSP", "performs", "similarly", "to", "strong", "seq2seq", "baselines", "on", "random", "splits", ",", "but", "dramatically", "improves", "performance", "compared", "to", "baselines", "on", "splits", "that", "require", "compositional", "generalization", ":", "from", "61.0", "\u2192", "88.9", "average", "accuracy", "."], "entities": [{"type": "Operation", "start": 143, "end": 144, "text": "SpanBasedSP", "sent_idx": 4}, {"type": "Effect", "start": 157, "end": 158, "text": "performance", "sent_idx": 4}, {"type": "Effect", "start": 172, "end": 174, "text": "average accuracy", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 0, "tail": 2}], "id": "abstract-2021--acl-long--74"}
{"text": "BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pretrained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension to better align the pre-training from memorization to understanding. Span Selection PreTraining (SSPT) poses cloze-like training instances, but rather than draw the answer from the model\u2019s parameters, it is selected from a relevant passage. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple Machine Reading Comprehension (MRC) datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also show significant impact in HotpotQA, improving answer prediction F1 by 4 points and supporting fact prediction F1 by 1 point and outperforming the previous best system. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.", "tokens": ["BERT", "(", "Bidirectional", "Encoder", "Representations", "from", "Transformers", ")", "and", "related", "pre-trained", "Transformers", "have", "provided", "large", "gains", "across", "many", "language", "understanding", "tasks", ",", "achieving", "a", "new", "state-of-the-art", "(", "SOTA", ")", ".", "BERT", "is", "pretrained", "on", "two", "auxiliary", "tasks", ":", "Masked", "Language", "Model", "and", "Next", "Sentence", "Prediction", ".", "In", "this", "paper", "we", "introduce", "a", "new", "pre-training", "task", "inspired", "by", "reading", "comprehension", "to", "better", "align", "the", "pre-training", "from", "memorization", "to", "understanding", ".", "Span", "Selection", "PreTraining", "(", "SSPT", ")", "poses", "cloze-like", "training", "instances", ",", "but", "rather", "than", "draw", "the", "answer", "from", "the", "model", "\u2019s", "parameters", ",", "it", "is", "selected", "from", "a", "relevant", "passage", ".", "We", "find", "significant", "and", "consistent", "improvements", "over", "both", "BERT-BASE", "and", "BERT-LARGE", "on", "multiple", "Machine", "Reading", "Comprehension", "(", "MRC", ")", "datasets", ".", "Specifically", ",", "our", "proposed", "model", "has", "strong", "empirical", "evidence", "as", "it", "obtains", "SOTA", "results", "on", "Natural", "Questions", ",", "a", "new", "benchmark", "MRC", "dataset", ",", "outperforming", "BERT-LARGE", "by", "3", "F1", "points", "on", "short", "answer", "prediction", ".", "We", "also", "show", "significant", "impact", "in", "HotpotQA", ",", "improving", "answer", "prediction", "F1", "by", "4", "points", "and", "supporting", "fact", "prediction", "F1", "by", "1", "point", "and", "outperforming", "the", "previous", "best", "system", ".", "Moreover", ",", "we", "show", "that", "our", "pre-training", "approach", "is", "particularly", "effective", "when", "training", "data", "is", "limited", ",", "improving", "the", "learning", "curve", "by", "a", "large", "amount", "."], "entities": [{"type": "Operation", "start": 50, "end": 55, "text": "introduce a new pre-training task", "sent_idx": 2}, {"type": "Effect", "start": 167, "end": 168, "text": "F1", "sent_idx": 6}, {"type": "Effect", "start": 175, "end": 176, "text": "F1", "sent_idx": 6}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 0, "tail": 2}], "id": "abstract-2020--acl-main--247"}
{"text": "Learning high-quality sentence representations benefits a wide range of natural language processing tasks. Though BERT-based pre-trained language models achieve high performance on many downstream tasks, the native derived sentence representations are proved to be collapsed and thus produce a poor performance on the semantic textual similarity (STS) tasks. In this paper, we present ConSERT, a Contrastive Framework for Self-Supervised SEntence Representation Transfer, that adopts contrastive learning to fine-tune BERT in an unsupervised and effective way. By making use of unlabeled texts, ConSERT solves the collapse issue of BERT-derived sentence representations and make them more applicable for downstream tasks. Experiments on STS datasets demonstrate that ConSERT achieves an 8% relative improvement over the previous state-of-the-art, even comparable to the supervised SBERT-NLI. And when further incorporating NLI supervision, we achieve new state-of-the-art performance on STS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples available, showing its robustness in data scarcity scenarios.", "tokens": ["Learning", "high-quality", "sentence", "representations", "benefits", "a", "wide", "range", "of", "natural", "language", "processing", "tasks", ".", "Though", "BERT-based", "pre-trained", "language", "models", "achieve", "high", "performance", "on", "many", "downstream", "tasks", ",", "the", "native", "derived", "sentence", "representations", "are", "proved", "to", "be", "collapsed", "and", "thus", "produce", "a", "poor", "performance", "on", "the", "semantic", "textual", "similarity", "(", "STS", ")", "tasks", ".", "In", "this", "paper", ",", "we", "present", "ConSERT", ",", "a", "Contrastive", "Framework", "for", "Self-Supervised", "SEntence", "Representation", "Transfer", ",", "that", "adopts", "contrastive", "learning", "to", "fine-tune", "BERT", "in", "an", "unsupervised", "and", "effective", "way", ".", "By", "making", "use", "of", "unlabeled", "texts", ",", "ConSERT", "solves", "the", "collapse", "issue", "of", "BERT-derived", "sentence", "representations", "and", "make", "them", "more", "applicable", "for", "downstream", "tasks", ".", "Experiments", "on", "STS", "datasets", "demonstrate", "that", "ConSERT", "achieves", "an", "8", "%", "relative", "improvement", "over", "the", "previous", "state-of-the-art", ",", "even", "comparable", "to", "the", "supervised", "SBERT-NLI", ".", "And", "when", "further", "incorporating", "NLI", "supervision", ",", "we", "achieve", "new", "state-of-the-art", "performance", "on", "STS", "tasks", ".", "Moreover", ",", "ConSERT", "obtains", "comparable", "results", "with", "only", "1000", "samples", "available", ",", "showing", "its", "robustness", "in", "data", "scarcity", "scenarios", "."], "entities": [{"type": "Operation", "start": 152, "end": 153, "text": "ConSERT", "sent_idx": 6}, {"type": "Effect", "start": 164, "end": 165, "text": "robustness", "sent_idx": 6}], "relations": [{"type": "Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--393"}
{"text": "Identifying background (context) information in scientific articles can help scholars understand major contributions in their research area more easily. In this paper, we propose a general framework based on probabilistic inference to extract such context information from scientific papers. We model the sentences in an article and their lexical similarities as a Markov Random Field tuned to detect the patterns that context data create, and employ a Belief Propagation mechanism to detect likely context sentences. We also address the problem of generating surveys of scientific papers. Our experiments show greater pyramid scores for surveys generated using such context information rather than citation sentences alone.", "tokens": ["Identifying", "background", "(", "context", ")", "information", "in", "scientific", "articles", "can", "help", "scholars", "understand", "major", "contributions", "in", "their", "research", "area", "more", "easily", ".", "In", "this", "paper", ",", "we", "propose", "a", "general", "framework", "based", "on", "probabilistic", "inference", "to", "extract", "such", "context", "information", "from", "scientific", "papers", ".", "We", "model", "the", "sentences", "in", "an", "article", "and", "their", "lexical", "similarities", "as", "a", "Markov", "Random", "Field", "tuned", "to", "detect", "the", "patterns", "that", "context", "data", "create", ",", "and", "employ", "a", "Belief", "Propagation", "mechanism", "to", "detect", "likely", "context", "sentences", ".", "We", "also", "address", "the", "problem", "of", "generating", "surveys", "of", "scientific", "papers", ".", "Our", "experiments", "show", "greater", "pyramid", "scores", "for", "surveys", "generated", "using", "such", "context", "information", "rather", "than", "citation", "sentences", "alone", "."], "entities": [{"type": "Operation", "start": 103, "end": 107, "text": "using such context information", "sent_idx": 4}, {"type": "Effect", "start": 98, "end": 100, "text": "pyramid scores", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "P10-1057"}
{"text": "Joint extraction of entities and relations from unstructured texts is a crucial task in information extraction. Recent methods achieve considerable performance but still suffer from some inherent limitations, such as redundancy of relation prediction, poor generalization of span-based extraction and inefficiency. In this paper, we decompose this task into three subtasks, Relation Judgement, Entity Extraction and Subject-object Alignment from a novel perspective and then propose a joint relational triple extraction framework based on Potential Relation and Global Correspondence (PRGC). Specifically, we design a component to predict potential relations, which constrains the following entity extraction to the predicted relation subset rather than all relations; then a relation-specific sequence tagging component is applied to handle the overlapping problem between subjects and objects; finally, a global correspondence component is designed to align the subject and object into a triple with low-complexity. Extensive experiments show that PRGC achieves state-of-the-art performance on public benchmarks with higher efficiency and delivers consistent performance gain on complex scenarios of overlapping triples. The source code has been submitted as the supplementary material and will be made publicly available after the blind review.", "tokens": ["Joint", "extraction", "of", "entities", "and", "relations", "from", "unstructured", "texts", "is", "a", "crucial", "task", "in", "information", "extraction", ".", "Recent", "methods", "achieve", "considerable", "performance", "but", "still", "suffer", "from", "some", "inherent", "limitations", ",", "such", "as", "redundancy", "of", "relation", "prediction", ",", "poor", "generalization", "of", "span-based", "extraction", "and", "inefficiency", ".", "In", "this", "paper", ",", "we", "decompose", "this", "task", "into", "three", "subtasks", ",", "Relation", "Judgement", ",", "Entity", "Extraction", "and", "Subject-object", "Alignment", "from", "a", "novel", "perspective", "and", "then", "propose", "a", "joint", "relational", "triple", "extraction", "framework", "based", "on", "Potential", "Relation", "and", "Global", "Correspondence", "(", "PRGC", ")", ".", "Specifically", ",", "we", "design", "a", "component", "to", "predict", "potential", "relations", ",", "which", "constrains", "the", "following", "entity", "extraction", "to", "the", "predicted", "relation", "subset", "rather", "than", "all", "relations", ";", "then", "a", "relation-specific", "sequence", "tagging", "component", "is", "applied", "to", "handle", "the", "overlapping", "problem", "between", "subjects", "and", "objects", ";", "finally", ",", "a", "global", "correspondence", "component", "is", "designed", "to", "align", "the", "subject", "and", "object", "into", "a", "triple", "with", "low-complexity", ".", "Extensive", "experiments", "show", "that", "PRGC", "achieves", "state-of-the-art", "performance", "on", "public", "benchmarks", "with", "higher", "efficiency", "and", "delivers", "consistent", "performance", "gain", "on", "complex", "scenarios", "of", "overlapping", "triples", ".", "The", "source", "code", "has", "been", "submitted", "as", "the", "supplementary", "material", "and", "will", "be", "made", "publicly", "available", "after", "the", "blind", "review", "."], "entities": [{"type": "Operation", "start": 158, "end": 159, "text": "PRGC", "sent_idx": 4}, {"type": "Effect", "start": 161, "end": 162, "text": "performance", "sent_idx": 4}, {"type": "Effect", "start": 167, "end": 168, "text": "efficiency", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 0, "tail": 2}], "id": "abstract-2021--acl-long--486"}
{"text": "Knowledge distillation (KD) is commonly used to construct synthetic data for training non-autoregressive translation (NAT) models. However, there exists a discrepancy on low-frequency words between the distilled and the original data, leading to more errors on predicting low-frequency words. To alleviate the problem, we directly expose the raw data into NAT by leveraging pretraining. By analyzing directed alignments, we found that KD makes low-frequency source words aligned with targets more deterministically but fails to align sufficient low-frequency words from target to source. Accordingly, we propose reverse KD to rejuvenate more alignments for low-frequency target words. To make the most of authentic and synthetic data, we combine these complementary approaches as a new training strategy for further boosting NAT performance. We conduct experiments on five translation benchmarks over two advanced architectures. Results demonstrate that the proposed approach can significantly and universally improve translation quality by reducing translation errors on low-frequency words. Encouragingly, our approach achieves 28.2 and 33.9 BLEU points on the WMT14 English-German and WMT16 Romanian-English datasets, respectively. Our code, data, and trained models are available at https://github.com/longyuewangdcu/RLFW-NAT .", "tokens": ["Knowledge", "distillation", "(", "KD", ")", "is", "commonly", "used", "to", "construct", "synthetic", "data", "for", "training", "non-autoregressive", "translation", "(", "NAT", ")", "models", ".", "However", ",", "there", "exists", "a", "discrepancy", "on", "low-frequency", "words", "between", "the", "distilled", "and", "the", "original", "data", ",", "leading", "to", "more", "errors", "on", "predicting", "low-frequency", "words", ".", "To", "alleviate", "the", "problem", ",", "we", "directly", "expose", "the", "raw", "data", "into", "NAT", "by", "leveraging", "pretraining", ".", "By", "analyzing", "directed", "alignments", ",", "we", "found", "that", "KD", "makes", "low-frequency", "source", "words", "aligned", "with", "targets", "more", "deterministically", "but", "fails", "to", "align", "sufficient", "low-frequency", "words", "from", "target", "to", "source", ".", "Accordingly", ",", "we", "propose", "reverse", "KD", "to", "rejuvenate", "more", "alignments", "for", "low-frequency", "target", "words", ".", "To", "make", "the", "most", "of", "authentic", "and", "synthetic", "data", ",", "we", "combine", "these", "complementary", "approaches", "as", "a", "new", "training", "strategy", "for", "further", "boosting", "NAT", "performance", ".", "We", "conduct", "experiments", "on", "five", "translation", "benchmarks", "over", "two", "advanced", "architectures", ".", "Results", "demonstrate", "that", "the", "proposed", "approach", "can", "significantly", "and", "universally", "improve", "translation", "quality", "by", "reducing", "translation", "errors", "on", "low-frequency", "words", ".", "Encouragingly", ",", "our", "approach", "achieves", "28.2", "and", "33.9", "BLEU", "points", "on", "the", "WMT14", "English-German", "and", "WMT16", "Romanian-English", "datasets", ",", "respectively", ".", "Our", "code", ",", "data", ",", "and", "trained", "models", "are", "available", "at", "https://github.com/longyuewangdcu/RLFW-NAT", "."], "entities": [{"type": "Operation", "start": 120, "end": 129, "text": "combine these complementary approaches as a new training strategy", "sent_idx": 5}, {"type": "Effect", "start": 133, "end": 134, "text": "performance", "sent_idx": 5}, {"type": "Effect", "start": 176, "end": 178, "text": "BLEU points", "sent_idx": 8}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}], "id": "abstract-2021--acl-long--266"}
{"text": "The standard training algorithm in neural machine translation (NMT) suffers from exposure bias, and alternative algorithms have been proposed to mitigate this. However, the practical impact of exposure bias is under debate. In this paper, we link exposure bias to another well-known problem in NMT, namely the tendency to generate hallucinations under domain shift. In experiments on three datasets with multiple test domains, we show that exposure bias is partially to blame for hallucinations, and that training with Minimum Risk Training, which avoids exposure bias, can mitigate this. Our analysis explains why exposure bias is more problematic under domain shift, and also links exposure bias to the beam search problem, i.e. performance deterioration with increasing beam size. Our results provide a new justification for methods that reduce exposure bias: even if they do not increase performance on in-domain test sets, they can increase model robustness to domain shift.", "tokens": ["The", "standard", "training", "algorithm", "in", "neural", "machine", "translation", "(", "NMT", ")", "suffers", "from", "exposure", "bias", ",", "and", "alternative", "algorithms", "have", "been", "proposed", "to", "mitigate", "this", ".", "However", ",", "the", "practical", "impact", "of", "exposure", "bias", "is", "under", "debate", ".", "In", "this", "paper", ",", "we", "link", "exposure", "bias", "to", "another", "well-known", "problem", "in", "NMT", ",", "namely", "the", "tendency", "to", "generate", "hallucinations", "under", "domain", "shift", ".", "In", "experiments", "on", "three", "datasets", "with", "multiple", "test", "domains", ",", "we", "show", "that", "exposure", "bias", "is", "partially", "to", "blame", "for", "hallucinations", ",", "and", "that", "training", "with", "Minimum", "Risk", "Training", ",", "which", "avoids", "exposure", "bias", ",", "can", "mitigate", "this", ".", "Our", "analysis", "explains", "why", "exposure", "bias", "is", "more", "problematic", "under", "domain", "shift", ",", "and", "also", "links", "exposure", "bias", "to", "the", "beam", "search", "problem", ",", "i.e.", "performance", "deterioration", "with", "increasing", "beam", "size", ".", "Our", "results", "provide", "a", "new", "justification", "for", "methods", "that", "reduce", "exposure", "bias", ":", "even", "if", "they", "do", "not", "increase", "performance", "on", "in-domain", "test", "sets", ",", "they", "can", "increase", "model", "robustness", "to", "domain", "shift", "."], "entities": [{"type": "Operation", "start": 130, "end": 133, "text": "increasing beam size", "sent_idx": 4}, {"type": "Effect", "start": 127, "end": 128, "text": "performance", "sent_idx": 4}], "relations": [{"type": "Neg_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--326"}
{"text": "We present a simple but effective method for aspect identification in sentiment analysis. Our unsupervised method only requires word embeddings and a POS tagger, and is therefore straightforward to apply to new domains and languages. We introduce Contrastive Attention (CAt), a novel single-head attention mechanism based on an RBF kernel, which gives a considerable boost in performance and makes the model interpretable. Previous work relied on syntactic features and complex neural models. We show that given the simplicity of current benchmark datasets for aspect extraction, such complex models are not needed. The code to reproduce the experiments reported in this paper is available at https://github.com/clips/cat.", "tokens": ["We", "present", "a", "simple", "but", "effective", "method", "for", "aspect", "identification", "in", "sentiment", "analysis", ".", "Our", "unsupervised", "method", "only", "requires", "word", "embeddings", "and", "a", "POS", "tagger", ",", "and", "is", "therefore", "straightforward", "to", "apply", "to", "new", "domains", "and", "languages", ".", "We", "introduce", "Contrastive", "Attention", "(", "CAt", ")", ",", "a", "novel", "single-head", "attention", "mechanism", "based", "on", "an", "RBF", "kernel", ",", "which", "gives", "a", "considerable", "boost", "in", "performance", "and", "makes", "the", "model", "interpretable", ".", "Previous", "work", "relied", "on", "syntactic", "features", "and", "complex", "neural", "models", ".", "We", "show", "that", "given", "the", "simplicity", "of", "current", "benchmark", "datasets", "for", "aspect", "extraction", ",", "such", "complex", "models", "are", "not", "needed", ".", "The", "code", "to", "reproduce", "the", "experiments", "reported", "in", "this", "paper", "is", "available", "at", "https://github.com/clips/cat", "."], "entities": [{"type": "Operation", "start": 40, "end": 45, "text": "Contrastive Attention (CAt)", "sent_idx": 2}, {"type": "Effect", "start": 63, "end": 64, "text": "performance", "sent_idx": 2}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--290"}
{"text": "Tree-to-string translation is syntax-aware and efficient but sensitive to parsing errors. Forest-to-string translation approaches mitigate the risk of propagating parser errors into translation errors by considering a forest of alternative trees, as generated by a source language parser. We propose an alternative approach to generating forests that is based on combining sub-trees within the first best parse through binarization. Provably, our binarization forest can cover any non-consitituent phrases in a sentence but maintains the desirable property that for each span there is at most one nonterminal so that the grammar constant for decoding is relatively small. For the purpose of reducing search errors, we apply the synchronous binarization technique to forest-to-string decoding. Combining the two techniques, we show that using a fast shift-reduce parser we can achieve significant quality gains in NIST 2008 English-to-Chinese track (1.3 BLEU points over a phrase-based system, 0.8 BLEU points over a hierarchical phrase-based system). Consistent and significant gains are also shown in WMT 2010 in the English to German, French, Spanish and Czech tracks.", "tokens": ["Tree-to-string", "translation", "is", "syntax-aware", "and", "efficient", "but", "sensitive", "to", "parsing", "errors", ".", "Forest-to-string", "translation", "approaches", "mitigate", "the", "risk", "of", "propagating", "parser", "errors", "into", "translation", "errors", "by", "considering", "a", "forest", "of", "alternative", "trees", ",", "as", "generated", "by", "a", "source", "language", "parser", ".", "We", "propose", "an", "alternative", "approach", "to", "generating", "forests", "that", "is", "based", "on", "combining", "sub-trees", "within", "the", "first", "best", "parse", "through", "binarization", ".", "Provably", ",", "our", "binarization", "forest", "can", "cover", "any", "non-consitituent", "phrases", "in", "a", "sentence", "but", "maintains", "the", "desirable", "property", "that", "for", "each", "span", "there", "is", "at", "most", "one", "nonterminal", "so", "that", "the", "grammar", "constant", "for", "decoding", "is", "relatively", "small", ".", "For", "the", "purpose", "of", "reducing", "search", "errors", ",", "we", "apply", "the", "synchronous", "binarization", "technique", "to", "forest-to-string", "decoding", ".", "Combining", "the", "two", "techniques", ",", "we", "show", "that", "using", "a", "fast", "shift-reduce", "parser", "we", "can", "achieve", "significant", "quality", "gains", "in", "NIST", "2008", "English-to-Chinese", "track", "(", "1.3", "BLEU", "points", "over", "a", "phrase-based", "system", ",", "0.8", "BLEU", "points", "over", "a", "hierarchical", "phrase-based", "system", ")", ".", "Consistent", "and", "significant", "gains", "are", "also", "shown", "in", "WMT", "2010", "in", "the", "English", "to", "German", ",", "French", ",", "Spanish", "and", "Czech", "tracks", "."], "entities": [{"type": "Operation", "start": 128, "end": 133, "text": "using a fast shift-reduce parser", "sent_idx": 5}, {"type": "Effect", "start": 146, "end": 148, "text": "BLEU points", "sent_idx": 5}, {"type": "Effect", "start": 154, "end": 156, "text": "BLEU points", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 0, "tail": 2}], "id": "P11-1084"}
{"text": "We propose a translation recommendation framework to integrate Statistical Machine Translation (SMT) output with Translation Memory (TM) systems. The framework recommends SMT outputs to a TM user when it predicts that SMT outputs are more suitable for post-editing than the hits provided by the TM. We describe an implementation of this framework using an SVM binary classifier. We exploit methods to fine-tune the classifier and investigate a variety of features of different types. We rely on automatic MT evaluation metrics to approximate human judgements in our experiments. Experimental results show that our system can achieve 0.85 precision at 0.89 recall, excluding exact matches. Furthermore, it is possible for the end-user to achieve a desired balance between precision and recall by adjusting confidence levels.", "tokens": ["We", "propose", "a", "translation", "recommendation", "framework", "to", "integrate", "Statistical", "Machine", "Translation", "(", "SMT", ")", "output", "with", "Translation", "Memory", "(", "TM", ")", "systems", ".", "The", "framework", "recommends", "SMT", "outputs", "to", "a", "TM", "user", "when", "it", "predicts", "that", "SMT", "outputs", "are", "more", "suitable", "for", "post-editing", "than", "the", "hits", "provided", "by", "the", "TM", ".", "We", "describe", "an", "implementation", "of", "this", "framework", "using", "an", "SVM", "binary", "classifier", ".", "We", "exploit", "methods", "to", "fine-tune", "the", "classifier", "and", "investigate", "a", "variety", "of", "features", "of", "different", "types", ".", "We", "rely", "on", "automatic", "MT", "evaluation", "metrics", "to", "approximate", "human", "judgements", "in", "our", "experiments", ".", "Experimental", "results", "show", "that", "our", "system", "can", "achieve", "0.85", "precision", "at", "0.89", "recall", ",", "excluding", "exact", "matches", ".", "Furthermore", ",", "it", "is", "possible", "for", "the", "end-user", "to", "achieve", "a", "desired", "balance", "between", "precision", "and", "recall", "by", "adjusting", "confidence", "levels", "."], "entities": [{"type": "Operation", "start": 7, "end": 22, "text": "integrate Statistical Machine Translation (SMT) output with Translation Memory (TM) systems", "sent_idx": 0}, {"type": "Effect", "start": 105, "end": 106, "text": "precision", "sent_idx": 5}, {"type": "Effect", "start": 108, "end": 109, "text": "recall", "sent_idx": 5}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}], "id": "P10-1064"}
{"text": "Comparing one thing with another is a typical part of human decision making process. However, it is not always easy to know what to compare and what are the alternatives. In this paper, we present a novel way to automatically mine comparable entities from comparative questions that users posted online to address this difficulty. To ensure high precision and high recall, we develop a weakly supervised bootstrapping approach for comparative question identification and comparable entity extraction by leveraging a large collection of online question archive. The experimental results show our method achieves F1-measure of 82.5 percent in comparative question identification and 83.3 percent in comparable entity extraction. Both significantly outperform an existing state-of-the-art method. Additionally, our ranking results show highly relevance to user's comparison intents in web.", "tokens": ["Comparing", "one", "thing", "with", "another", "is", "a", "typical", "part", "of", "human", "decision", "making", "process", ".", "However", ",", "it", "is", "not", "always", "easy", "to", "know", "what", "to", "compare", "and", "what", "are", "the", "alternatives", ".", "In", "this", "paper", ",", "we", "present", "a", "novel", "way", "to", "automatically", "mine", "comparable", "entities", "from", "comparative", "questions", "that", "users", "posted", "online", "to", "address", "this", "difficulty", ".", "To", "ensure", "high", "precision", "and", "high", "recall", ",", "we", "develop", "a", "weakly", "supervised", "bootstrapping", "approach", "for", "comparative", "question", "identification", "and", "comparable", "entity", "extraction", "by", "leveraging", "a", "large", "collection", "of", "online", "question", "archive", ".", "The", "experimental", "results", "show", "our", "method", "achieves", "F1-measure", "of", "82.5", "percent", "in", "comparative", "question", "identification", "and", "83.3", "percent", "in", "comparable", "entity", "extraction", ".", "Both", "significantly", "outperform", "an", "existing", "state-of-the-art", "method", ".", "Additionally", ",", "our", "ranking", "results", "show", "highly", "relevance", "to", "user", "'s", "comparison", "intents", "in", "web", "."], "entities": [{"type": "Operation", "start": 70, "end": 74, "text": "weakly supervised bootstrapping approach", "sent_idx": 3}, {"type": "Effect", "start": 65, "end": 66, "text": "recall", "sent_idx": 3}, {"type": "Effect", "start": 62, "end": 63, "text": "precision", "sent_idx": 3}, {"type": "Effect", "start": 99, "end": 100, "text": "F1-measure", "sent_idx": 4}], "relations": [{"type": "Affect", "head": 0, "tail": 1}, {"type": "Affect", "head": 0, "tail": 2}, {"type": "Affect", "head": 0, "tail": 3}], "id": "P10-1067"}
{"text": "A major obstacle in Word Sense Disambiguation (WSD) is that word senses are not uniformly distributed, causing existing models to generally perform poorly on senses that are either rare or unseen during training. We propose a bi-encoder model that independently embeds (1) the target word with its surrounding context and (2) the dictionary definition, or gloss, of each sense. The encoders are jointly optimized in the same representation space, so that sense disambiguation can be performed by finding the nearest sense embedding for each target word embedding. Our system outperforms previous state-of-the-art models on English all-words WSD; these gains predominantly come from improved performance on rare senses, leading to a 31.1% error reduction on less frequent senses over prior work. This demonstrates that rare senses can be more effectively disambiguated by modeling their definitions.", "tokens": ["A", "major", "obstacle", "in", "Word", "Sense", "Disambiguation", "(", "WSD", ")", "is", "that", "word", "senses", "are", "not", "uniformly", "distributed", ",", "causing", "existing", "models", "to", "generally", "perform", "poorly", "on", "senses", "that", "are", "either", "rare", "or", "unseen", "during", "training", ".", "We", "propose", "a", "bi-encoder", "model", "that", "independently", "embeds", "(", "1", ")", "the", "target", "word", "with", "its", "surrounding", "context", "and", "(", "2", ")", "the", "dictionary", "definition", ",", "or", "gloss", ",", "of", "each", "sense", ".", "The", "encoders", "are", "jointly", "optimized", "in", "the", "same", "representation", "space", ",", "so", "that", "sense", "disambiguation", "can", "be", "performed", "by", "finding", "the", "nearest", "sense", "embedding", "for", "each", "target", "word", "embedding", ".", "Our", "system", "outperforms", "previous", "state-of-the-art", "models", "on", "English", "all-words", "WSD", ";", "these", "gains", "predominantly", "come", "from", "improved", "performance", "on", "rare", "senses", ",", "leading", "to", "a", "31.1", "%", "error", "reduction", "on", "less", "frequent", "senses", "over", "prior", "work", ".", "This", "demonstrates", "that", "rare", "senses", "can", "be", "more", "effectively", "disambiguated", "by", "modeling", "their", "definitions", "."], "entities": [{"type": "Operation", "start": 40, "end": 42, "text": "bi-encoder model", "sent_idx": 1}, {"type": "Effect", "start": 117, "end": 118, "text": "performance", "sent_idx": 3}, {"type": "Effect", "start": 127, "end": 128, "text": "error", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Neg_Affect", "head": 0, "tail": 2}], "id": "abstract-2020--acl-main--95"}
{"text": "Recently, the performance of Pre-trained Language Models (PLMs) has been significantly improved by injecting knowledge facts to enhance their abilities of language understanding. For medical domains, the background knowledge sources are especially useful, due to the massive medical terms and their complicated relations are difficult to understand in text. In this work, we introduce SMedBERT, a medical PLM trained on large-scale medical corpora, incorporating deep structured semantic knowledge from neighbours of linked-entity. In SMedBERT, the mention-neighbour hybrid attention is proposed to learn heterogeneous-entity information, which infuses the semantic representations of entity types into the homogeneous neighbouring entity structure. Apart from knowledge integration as external features, we propose to employ the neighbors of linked-entities in the knowledge graph as additional global contexts of text mentions, allowing them to communicate via shared neighbors, thus enrich their semantic representations. Experiments demonstrate that SMedBERT significantly outperforms strong baselines in various knowledge-intensive Chinese medical tasks. It also improves the performance of other tasks such as question answering, question matching and natural language inference.", "tokens": ["Recently", ",", "the", "performance", "of", "Pre-trained", "Language", "Models", "(", "PLMs", ")", "has", "been", "significantly", "improved", "by", "injecting", "knowledge", "facts", "to", "enhance", "their", "abilities", "of", "language", "understanding", ".", "For", "medical", "domains", ",", "the", "background", "knowledge", "sources", "are", "especially", "useful", ",", "due", "to", "the", "massive", "medical", "terms", "and", "their", "complicated", "relations", "are", "difficult", "to", "understand", "in", "text", ".", "In", "this", "work", ",", "we", "introduce", "SMedBERT", ",", "a", "medical", "PLM", "trained", "on", "large-scale", "medical", "corpora", ",", "incorporating", "deep", "structured", "semantic", "knowledge", "from", "neighbours", "of", "linked-entity", ".", "In", "SMedBERT", ",", "the", "mention-neighbour", "hybrid", "attention", "is", "proposed", "to", "learn", "heterogeneous-entity", "information", ",", "which", "infuses", "the", "semantic", "representations", "of", "entity", "types", "into", "the", "homogeneous", "neighbouring", "entity", "structure", ".", "Apart", "from", "knowledge", "integration", "as", "external", "features", ",", "we", "propose", "to", "employ", "the", "neighbors", "of", "linked-entities", "in", "the", "knowledge", "graph", "as", "additional", "global", "contexts", "of", "text", "mentions", ",", "allowing", "them", "to", "communicate", "via", "shared", "neighbors", ",", "thus", "enrich", "their", "semantic", "representations", ".", "Experiments", "demonstrate", "that", "SMedBERT", "significantly", "outperforms", "strong", "baselines", "in", "various", "knowledge-intensive", "Chinese", "medical", "tasks", ".", "It", "also", "improves", "the", "performance", "of", "other", "tasks", "such", "as", "question", "answering", ",", "question", "matching", "and", "natural", "language", "inference", "."], "entities": [{"type": "Operation", "start": 157, "end": 158, "text": "SMedBERT", "sent_idx": 5}, {"type": "Effect", "start": 173, "end": 174, "text": "performance", "sent_idx": 6}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2021--acl-long--457"}
{"text": "In this paper, we adopt an n-best rescoring scheme using pitch-accent patterns to improve automatic speech recognition (ASR) performance. The pitch-accent model is decoupled from the main ASR system, thus allowing us to develop it independently. N-best hypotheses from recognizers are rescored by additional scores that measure the correlation of the pitch-accent patterns between the acoustic signal and lexical cues. To test the robustness of our algorithm, we use two different data sets and recognition setups: the first one is English radio news data that has pitch accent labels, but the recognizer is trained from a small amount of data and has high error rate; the second one is English broadcast news data using a state-of-the-art SRI recognizer. Our experimental results demonstrate that our approach is able to reduce word error rate relatively by about 3%. This gain is consistent across the two different tests, showing promising future directions of incorporating prosodic information to improve speech recognition.", "tokens": ["In", "this", "paper", ",", "we", "adopt", "an", "n-best", "rescoring", "scheme", "using", "pitch-accent", "patterns", "to", "improve", "automatic", "speech", "recognition", "(", "ASR", ")", "performance", ".", "The", "pitch-accent", "model", "is", "decoupled", "from", "the", "main", "ASR", "system", ",", "thus", "allowing", "us", "to", "develop", "it", "independently", ".", "N-best", "hypotheses", "from", "recognizers", "are", "rescored", "by", "additional", "scores", "that", "measure", "the", "correlation", "of", "the", "pitch-accent", "patterns", "between", "the", "acoustic", "signal", "and", "lexical", "cues", ".", "To", "test", "the", "robustness", "of", "our", "algorithm", ",", "we", "use", "two", "different", "data", "sets", "and", "recognition", "setups", ":", "the", "first", "one", "is", "English", "radio", "news", "data", "that", "has", "pitch", "accent", "labels", ",", "but", "the", "recognizer", "is", "trained", "from", "a", "small", "amount", "of", "data", "and", "has", "high", "error", "rate", ";", "the", "second", "one", "is", "English", "broadcast", "news", "data", "using", "a", "state-of-the-art", "SRI", "recognizer", ".", "Our", "experimental", "results", "demonstrate", "that", "our", "approach", "is", "able", "to", "reduce", "word", "error", "rate", "relatively", "by", "about", "3", "%", ".", "This", "gain", "is", "consistent", "across", "the", "two", "different", "tests", ",", "showing", "promising", "future", "directions", "of", "incorporating", "prosodic", "information", "to", "improve", "speech", "recognition", "."], "entities": [{"type": "Operation", "start": 7, "end": 13, "text": "n-best rescoring scheme using pitch-accent patterns", "sent_idx": 0}, {"type": "Effect", "start": 21, "end": 22, "text": "performance", "sent_idx": 0}, {"type": "Effect", "start": 141, "end": 144, "text": "word error rate", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Neg_Affect", "head": 0, "tail": 2}], "id": "P11-1074"}
{"text": "Recently, the sequence-to-sequence models have made remarkable progress on the task of keyphrase generation (KG) by concatenating multiple keyphrases in a predefined order as a target sequence during training. However, the keyphrases are inherently an unordered set rather than an ordered sequence. Imposing a predefined order will introduce wrong bias during training, which can highly penalize shifts in the order between keyphrases. In this work, we propose a new training paradigm One2Set without predefining an order to concatenate the keyphrases. To fit this paradigm, we propose a novel model that utilizes a fixed set of learned control codes as conditions to generate a set of keyphrases in parallel. To solve the problem that there is no correspondence between each prediction and target during training, we propose a K-step label assignment mechanism via bipartite matching, which greatly increases the diversity and reduces the repetition rate of generated keyphrases. The experimental results on multiple benchmarks demonstrate that our approach significantly outperforms the state-of-the-art methods.", "tokens": ["Recently", ",", "the", "sequence-to-sequence", "models", "have", "made", "remarkable", "progress", "on", "the", "task", "of", "keyphrase", "generation", "(", "KG", ")", "by", "concatenating", "multiple", "keyphrases", "in", "a", "predefined", "order", "as", "a", "target", "sequence", "during", "training", ".", "However", ",", "the", "keyphrases", "are", "inherently", "an", "unordered", "set", "rather", "than", "an", "ordered", "sequence", ".", "Imposing", "a", "predefined", "order", "will", "introduce", "wrong", "bias", "during", "training", ",", "which", "can", "highly", "penalize", "shifts", "in", "the", "order", "between", "keyphrases", ".", "In", "this", "work", ",", "we", "propose", "a", "new", "training", "paradigm", "One2Set", "without", "predefining", "an", "order", "to", "concatenate", "the", "keyphrases", ".", "To", "fit", "this", "paradigm", ",", "we", "propose", "a", "novel", "model", "that", "utilizes", "a", "fixed", "set", "of", "learned", "control", "codes", "as", "conditions", "to", "generate", "a", "set", "of", "keyphrases", "in", "parallel", ".", "To", "solve", "the", "problem", "that", "there", "is", "no", "correspondence", "between", "each", "prediction", "and", "target", "during", "training", ",", "we", "propose", "a", "K-step", "label", "assignment", "mechanism", "via", "bipartite", "matching", ",", "which", "greatly", "increases", "the", "diversity", "and", "reduces", "the", "repetition", "rate", "of", "generated", "keyphrases", ".", "The", "experimental", "results", "on", "multiple", "benchmarks", "demonstrate", "that", "our", "approach", "significantly", "outperforms", "the", "state-of-the-art", "methods", "."], "entities": [{"type": "Operation", "start": 140, "end": 147, "text": "K-step label assignment mechanism via bipartite matching", "sent_idx": 5}, {"type": "Effect", "start": 152, "end": 153, "text": "diversity", "sent_idx": 5}, {"type": "Effect", "start": 156, "end": 158, "text": "repetition rate", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Neg_Affect", "head": 0, "tail": 2}], "id": "abstract-2021--acl-long--354"}
{"text": "This paper proposes a novel reordering model for statistical machine translation (SMT) by means of modeling the translation orders of the source language collocations. The model is learned from a word-aligned bilingual corpus where the collocated words in source sentences are automatically detected. During decoding, the model is employed to softly constrain the translation orders of the source language collocations, so as to constrain the translation orders of those source phrases containing these collocated words. The experimental results show that the proposed method significantly improves the translation quality, achieving the absolute improvements of 1.1~1.4 BLEU score over the baseline methods.", "tokens": ["This", "paper", "proposes", "a", "novel", "reordering", "model", "for", "statistical", "machine", "translation", "(", "SMT", ")", "by", "means", "of", "modeling", "the", "translation", "orders", "of", "the", "source", "language", "collocations", ".", "The", "model", "is", "learned", "from", "a", "word-aligned", "bilingual", "corpus", "where", "the", "collocated", "words", "in", "source", "sentences", "are", "automatically", "detected", ".", "During", "decoding", ",", "the", "model", "is", "employed", "to", "softly", "constrain", "the", "translation", "orders", "of", "the", "source", "language", "collocations", ",", "so", "as", "to", "constrain", "the", "translation", "orders", "of", "those", "source", "phrases", "containing", "these", "collocated", "words", ".", "The", "experimental", "results", "show", "that", "the", "proposed", "method", "significantly", "improves", "the", "translation", "quality", ",", "achieving", "the", "absolute", "improvements", "of", "1.1~1.4", "BLEU", "score", "over", "the", "baseline", "methods", "."], "entities": [{"type": "Operation", "start": 17, "end": 26, "text": "modeling the translation orders of the source language collocations", "sent_idx": 0}, {"type": "Effect", "start": 93, "end": 95, "text": "translation quality", "sent_idx": 3}, {"type": "Effect", "start": 102, "end": 104, "text": "BLEU score", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 0, "tail": 2}], "id": "P11-1104"}
{"text": "Deep reinforcement learning is a promising approach to training a dialog manager, but current methods struggle with the large state and action spaces of multi-domain dialog systems. Building upon Deep Q-learning from Demonstrations (DQfD), an algorithm that scores highly in difficult Atari games, we leverage dialog data to guide the agent to successfully respond to a user\u2019s requests. We make progressively fewer assumptions about the data needed, using labeled, reduced-labeled, and even unlabeled data to train expert demonstrators. We introduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to overcome the domain gap between the datasets and the environment. Experiments in a challenging multi-domain dialog system framework validate our approaches, and get high success rates even when trained on out-of-domain data.", "tokens": ["Deep", "reinforcement", "learning", "is", "a", "promising", "approach", "to", "training", "a", "dialog", "manager", ",", "but", "current", "methods", "struggle", "with", "the", "large", "state", "and", "action", "spaces", "of", "multi-domain", "dialog", "systems", ".", "Building", "upon", "Deep", "Q-learning", "from", "Demonstrations", "(", "DQfD", ")", ",", "an", "algorithm", "that", "scores", "highly", "in", "difficult", "Atari", "games", ",", "we", "leverage", "dialog", "data", "to", "guide", "the", "agent", "to", "successfully", "respond", "to", "a", "user", "\u2019s", "requests", ".", "We", "make", "progressively", "fewer", "assumptions", "about", "the", "data", "needed", ",", "using", "labeled", ",", "reduced-labeled", ",", "and", "even", "unlabeled", "data", "to", "train", "expert", "demonstrators", ".", "We", "introduce", "Reinforced", "Fine-tune", "Learning", ",", "an", "extension", "to", "DQfD", ",", "enabling", "us", "to", "overcome", "the", "domain", "gap", "between", "the", "datasets", "and", "the", "environment", ".", "Experiments", "in", "a", "challenging", "multi-domain", "dialog", "system", "framework", "validate", "our", "approaches", ",", "and", "get", "high", "success", "rates", "even", "when", "trained", "on", "out-of-domain", "data", "."], "entities": [{"type": "Operation", "start": 29, "end": 38, "text": "Building upon Deep Q-learning from Demonstrations (DQfD)", "sent_idx": 1}, {"type": "Effect", "start": 130, "end": 132, "text": "success rates", "sent_idx": 4}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--129"}
{"text": "We propose a novel linearization of a constituent tree, together with a new locally normalized model. For each split point in a sentence, our model computes the normalizer on all spans ending with that split point, and then predicts a tree span from them. Compared with global models, our model is fast and parallelizable. Different from previous local models, our linearization method is tied on the spans directly and considers more local features when performing span prediction, which is more interpretable and effective. Experiments on PTB (95.8 F1) and CTB (92.4 F1) show that our model significantly outperforms existing local models and efficiently achieves competitive results with global models.", "tokens": ["We", "propose", "a", "novel", "linearization", "of", "a", "constituent", "tree", ",", "together", "with", "a", "new", "locally", "normalized", "model", ".", "For", "each", "split", "point", "in", "a", "sentence", ",", "our", "model", "computes", "the", "normalizer", "on", "all", "spans", "ending", "with", "that", "split", "point", ",", "and", "then", "predicts", "a", "tree", "span", "from", "them", ".", "Compared", "with", "global", "models", ",", "our", "model", "is", "fast", "and", "parallelizable", ".", "Different", "from", "previous", "local", "models", ",", "our", "linearization", "method", "is", "tied", "on", "the", "spans", "directly", "and", "considers", "more", "local", "features", "when", "performing", "span", "prediction", ",", "which", "is", "more", "interpretable", "and", "effective", ".", "Experiments", "on", "PTB", "(", "95.8", "F1", ")", "and", "CTB", "(", "92.4", "F1", ")", "show", "that", "our", "model", "significantly", "outperforms", "existing", "local", "models", "and", "efficiently", "achieves", "competitive", "results", "with", "global", "models", "."], "entities": [{"type": "Operation", "start": 4, "end": 9, "text": "linearization of a constituent tree", "sent_idx": 0}, {"type": "Effect", "start": 98, "end": 99, "text": "F1", "sent_idx": 4}, {"type": "Operation", "start": 14, "end": 17, "text": "locally normalized model", "sent_idx": 0}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 2, "tail": 1}], "id": "abstract-2020--acl-main--299"}
{"text": "Pretraining deep language models has led to large performance gains in NLP. Despite this success, Schick and Sch\u00fctze (2020) recently showed that these models struggle to understand rare words. For static word embeddings, this problem has been addressed by separately learning representations for rare words. In this work, we transfer this idea to pretrained language models: We introduce BERTRAM, a powerful architecture based on BERT that is capable of inferring high-quality embeddings for rare words that are suitable as input representations for deep language models. This is achieved by enabling the surface form and contexts of a word to interact with each other in a deep architecture. Integrating BERTRAM into BERT leads to large performance increases due to improved representations of rare and medium frequency words on both a rare word probing task and three downstream tasks.", "tokens": ["Pretraining", "deep", "language", "models", "has", "led", "to", "large", "performance", "gains", "in", "NLP", ".", "Despite", "this", "success", ",", "Schick", "and", "Sch\u00fctze", "(", "2020", ")", "recently", "showed", "that", "these", "models", "struggle", "to", "understand", "rare", "words", ".", "For", "static", "word", "embeddings", ",", "this", "problem", "has", "been", "addressed", "by", "separately", "learning", "representations", "for", "rare", "words", ".", "In", "this", "work", ",", "we", "transfer", "this", "idea", "to", "pretrained", "language", "models", ":", "We", "introduce", "BERTRAM", ",", "a", "powerful", "architecture", "based", "on", "BERT", "that", "is", "capable", "of", "inferring", "high-quality", "embeddings", "for", "rare", "words", "that", "are", "suitable", "as", "input", "representations", "for", "deep", "language", "models", ".", "This", "is", "achieved", "by", "enabling", "the", "surface", "form", "and", "contexts", "of", "a", "word", "to", "interact", "with", "each", "other", "in", "a", "deep", "architecture", ".", "Integrating", "BERTRAM", "into", "BERT", "leads", "to", "large", "performance", "increases", "due", "to", "improved", "representations", "of", "rare", "and", "medium", "frequency", "words", "on", "both", "a", "rare", "word", "probing", "task", "and", "three", "downstream", "tasks", "."], "entities": [{"type": "Operation", "start": 119, "end": 123, "text": "Integrating BERTRAM into BERT", "sent_idx": 5}, {"type": "Effect", "start": 126, "end": 127, "text": "performance", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "abstract-2020--acl-main--368"}
{"text": "A range of studies have concluded that neural word prediction models can distinguish grammatical from ungrammatical sentences with high accuracy. However, these studies are based primarily on monolingual evidence from English. To investigate how these models\u2019 ability to learn syntax varies by language, we introduce CLAMS (Cross-Linguistic Assessment of Models on Syntax), a syntactic evaluation suite for monolingual and multilingual models. CLAMS includes subject-verb agreement challenge sets for English, French, German, Hebrew and Russian, generated from grammars we develop. We use CLAMS to evaluate LSTM language models as well as monolingual and multilingual BERT. Across languages, monolingual LSTMs achieved high accuracy on dependencies without attractors, and generally poor accuracy on agreement across object relative clauses. On other constructions, agreement accuracy was generally higher in languages with richer morphology. Multilingual models generally underperformed monolingual models. Multilingual BERT showed high syntactic accuracy on English, but noticeable deficiencies in other languages.", "tokens": ["A", "range", "of", "studies", "have", "concluded", "that", "neural", "word", "prediction", "models", "can", "distinguish", "grammatical", "from", "ungrammatical", "sentences", "with", "high", "accuracy", ".", "However", ",", "these", "studies", "are", "based", "primarily", "on", "monolingual", "evidence", "from", "English", ".", "To", "investigate", "how", "these", "models", "\u2019", "ability", "to", "learn", "syntax", "varies", "by", "language", ",", "we", "introduce", "CLAMS", "(", "Cross-Linguistic", "Assessment", "of", "Models", "on", "Syntax", ")", ",", "a", "syntactic", "evaluation", "suite", "for", "monolingual", "and", "multilingual", "models", ".", "CLAMS", "includes", "subject-verb", "agreement", "challenge", "sets", "for", "English", ",", "French", ",", "German", ",", "Hebrew", "and", "Russian", ",", "generated", "from", "grammars", "we", "develop", ".", "We", "use", "CLAMS", "to", "evaluate", "LSTM", "language", "models", "as", "well", "as", "monolingual", "and", "multilingual", "BERT", ".", "Across", "languages", ",", "monolingual", "LSTMs", "achieved", "high", "accuracy", "on", "dependencies", "without", "attractors", ",", "and", "generally", "poor", "accuracy", "on", "agreement", "across", "object", "relative", "clauses", ".", "On", "other", "constructions", ",", "agreement", "accuracy", "was", "generally", "higher", "in", "languages", "with", "richer", "morphology", ".", "Multilingual", "models", "generally", "underperformed", "monolingual", "models", ".", "Multilingual", "BERT", "showed", "high", "syntactic", "accuracy", "on", "English", ",", "but", "noticeable", "deficiencies", "in", "other", "languages", "."], "entities": [{"type": "Operation", "start": 109, "end": 114, "text": "Across languages, monolingual LSTMs", "sent_idx": 5}, {"type": "Effect", "start": 116, "end": 117, "text": "accuracy", "sent_idx": 5}, {"type": "Operation", "start": 155, "end": 157, "text": "Multilingual BERT", "sent_idx": 8}, {"type": "Effect", "start": 159, "end": 161, "text": "syntactic accuracy", "sent_idx": 8}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 2, "tail": 3}], "id": "abstract-2020--acl-main--490"}
{"text": "Conditional Random Fields (CRFs) are a widely-used approach for supervised sequence labelling, notably due to their ability to handle large description spaces and to integrate structural dependency between labels. Even for the simple linear-chain model, taking structure into account implies a number of parameters and a computational effort that grows quadratically with the cardinality of the label set. In this paper, we address the issue of training very large CRFs, containing up to hundreds output labels and several billion features. Efficiency stems here from the sparsity induced by the use of a l penalty term. Based on our own implementation, we compare three recent proposals for implementing this regularization strategy. Our experiments demonstrate that very large CRFs can be trained efficiently and that very large models are able to improve the accuracy, while delivering compact parameter sets.", "tokens": ["Conditional", "Random", "Fields", "(", "CRFs", ")", "are", "a", "widely-used", "approach", "for", "supervised", "sequence", "labelling", ",", "notably", "due", "to", "their", "ability", "to", "handle", "large", "description", "spaces", "and", "to", "integrate", "structural", "dependency", "between", "labels", ".", "Even", "for", "the", "simple", "linear-chain", "model", ",", "taking", "structure", "into", "account", "implies", "a", "number", "of", "parameters", "and", "a", "computational", "effort", "that", "grows", "quadratically", "with", "the", "cardinality", "of", "the", "label", "set", ".", "In", "this", "paper", ",", "we", "address", "the", "issue", "of", "training", "very", "large", "CRFs", ",", "containing", "up", "to", "hundreds", "output", "labels", "and", "several", "billion", "features", ".", "Efficiency", "stems", "here", "from", "the", "sparsity", "induced", "by", "the", "use", "of", "a", "l", "penalty", "term", ".", "Based", "on", "our", "own", "implementation", ",", "we", "compare", "three", "recent", "proposals", "for", "implementing", "this", "regularization", "strategy", ".", "Our", "experiments", "demonstrate", "that", "very", "large", "CRFs", "can", "be", "trained", "efficiently", "and", "that", "very", "large", "models", "are", "able", "to", "improve", "the", "accuracy", ",", "while", "delivering", "compact", "parameter", "sets", "."], "entities": [{"type": "Operation", "start": 128, "end": 129, "text": "CRFs", "sent_idx": 5}, {"type": "Effect", "start": 143, "end": 144, "text": "accuracy", "sent_idx": 5}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "P10-1052"}
{"text": "This paper presents hypothesis mixture decoding (HM decoding), a new decoding scheme that performs translation reconstruction using hypotheses generated by multiple translation systems. HM decoding involves two decoding stages: first, each component system decodes independently, with the explored search space kept for use in the next step; second, a new search space is constructed by composing existing hypotheses produced by all component systems using a set of rules provided by the HM decoder itself, and a new set of model independent features are used to seek the final best translation from this new search space. Few assumptions are made by our approach about the underlying component systems, enabling us to leverage SMT models based on arbitrary paradigms. We compare our approach with several related techniques, and demonstrate significant BLEU improvements in large-scale Chinese-to-English translation tasks.", "tokens": ["This", "paper", "presents", "hypothesis", "mixture", "decoding", "(", "HM", "decoding", ")", ",", "a", "new", "decoding", "scheme", "that", "performs", "translation", "reconstruction", "using", "hypotheses", "generated", "by", "multiple", "translation", "systems", ".", "HM", "decoding", "involves", "two", "decoding", "stages", ":", "first", ",", "each", "component", "system", "decodes", "independently", ",", "with", "the", "explored", "search", "space", "kept", "for", "use", "in", "the", "next", "step", ";", "second", ",", "a", "new", "search", "space", "is", "constructed", "by", "composing", "existing", "hypotheses", "produced", "by", "all", "component", "systems", "using", "a", "set", "of", "rules", "provided", "by", "the", "HM", "decoder", "itself", ",", "and", "a", "new", "set", "of", "model", "independent", "features", "are", "used", "to", "seek", "the", "final", "best", "translation", "from", "this", "new", "search", "space", ".", "Few", "assumptions", "are", "made", "by", "our", "approach", "about", "the", "underlying", "component", "systems", ",", "enabling", "us", "to", "leverage", "SMT", "models", "based", "on", "arbitrary", "paradigms", ".", "We", "compare", "our", "approach", "with", "several", "related", "techniques", ",", "and", "demonstrate", "significant", "BLEU", "improvements", "in", "large-scale", "Chinese-to-English", "translation", "tasks", "."], "entities": [{"type": "Operation", "start": 3, "end": 10, "text": "hypothesis mixture decoding (HM decoding)", "sent_idx": 0}, {"type": "Effect", "start": 142, "end": 143, "text": "BLEU", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}], "id": "P11-1126"}
{"text": "Knowledge Graph (KG) completion research usually focuses on densely connected benchmark datasets that are not representative of real KGs. We curate two KG datasets that include biomedical and encyclopedic knowledge and use an existing commonsense KG dataset to explore KG completion in the more realistic setting where dense connectivity is not guaranteed. We develop a deep convolutional network that utilizes textual entity representations and demonstrate that our model outperforms recent KG completion methods in this challenging setting. We find that our model\u2019s performance improvements stem primarily from its robustness to sparsity. We then distill the knowledge from the convolutional network into a student network that re-ranks promising candidate entities. This re-ranking stage leads to further improvements in performance and demonstrates the effectiveness of entity re-ranking for KG completion.", "tokens": ["Knowledge", "Graph", "(", "KG", ")", "completion", "research", "usually", "focuses", "on", "densely", "connected", "benchmark", "datasets", "that", "are", "not", "representative", "of", "real", "KGs", ".", "We", "curate", "two", "KG", "datasets", "that", "include", "biomedical", "and", "encyclopedic", "knowledge", "and", "use", "an", "existing", "commonsense", "KG", "dataset", "to", "explore", "KG", "completion", "in", "the", "more", "realistic", "setting", "where", "dense", "connectivity", "is", "not", "guaranteed", ".", "We", "develop", "a", "deep", "convolutional", "network", "that", "utilizes", "textual", "entity", "representations", "and", "demonstrate", "that", "our", "model", "outperforms", "recent", "KG", "completion", "methods", "in", "this", "challenging", "setting", ".", "We", "find", "that", "our", "model", "\u2019s", "performance", "improvements", "stem", "primarily", "from", "its", "robustness", "to", "sparsity", ".", "We", "then", "distill", "the", "knowledge", "from", "the", "convolutional", "network", "into", "a", "student", "network", "that", "re-ranks", "promising", "candidate", "entities", ".", "This", "re-ranking", "stage", "leads", "to", "further", "improvements", "in", "performance", "and", "demonstrates", "the", "effectiveness", "of", "entity", "re-ranking", "for", "KG", "completion", "."], "entities": [{"type": "Operation", "start": 118, "end": 120, "text": "re-ranking stage", "sent_idx": 5}, {"type": "Effect", "start": 125, "end": 126, "text": "performance", "sent_idx": 5}, {"type": "Operation", "start": 94, "end": 97, "text": "robustness to sparsity", "sent_idx": 3}, {"type": "Effect", "start": 88, "end": 89, "text": "performance", "sent_idx": 3}], "relations": [{"type": "Pos_Affect", "head": 0, "tail": 1}, {"type": "Pos_Affect", "head": 2, "tail": 3}], "id": "abstract-2021--acl-long--82"}
